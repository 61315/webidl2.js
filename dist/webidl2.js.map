{"version":3,"sources":["webpack://WebIDL2/webpack/universalModuleDefinition","webpack://WebIDL2/webpack/bootstrap","webpack://WebIDL2/./lib/productions/base.js","webpack://WebIDL2/./lib/error.js","webpack://WebIDL2/./lib/tokeniser.js","webpack://WebIDL2/./lib/productions/type.js","webpack://WebIDL2/./lib/productions/default.js","webpack://WebIDL2/./lib/productions/array-base.js","webpack://WebIDL2/./lib/productions/extended-attributes.js","webpack://WebIDL2/./lib/productions/helpers.js","webpack://WebIDL2/./lib/productions/argument.js","webpack://WebIDL2/./lib/productions/token.js","webpack://WebIDL2/./lib/productions/enum.js","webpack://WebIDL2/./lib/productions/includes.js","webpack://WebIDL2/./lib/webidl2.js","webpack://WebIDL2/./lib/writer.js","webpack://WebIDL2/./lib/validator.js","webpack://WebIDL2/./index.js"],"names":["root","factory","exports","module","define","amd","this","installedModules","__webpack_require__","moduleId","i","l","modules","call","m","c","d","name","getter","o","Object","defineProperty","enumerable","get","r","Symbol","toStringTag","value","t","mode","__esModule","ns","create","key","bind","n","object","property","prototype","hasOwnProperty","p","s","Base","[object Object]","source","tokens","defineProperties","json","type","undefined","inheritance","proto","descMap","getOwnPropertyDescriptors","entries","getPrototypeOf","error_error","position","current","message","sliceTokens","count","slice","Math","max","tokensToText","inputs","precedes","text","map","trivia","join","nextToken","length","line","precedingLine","splitted","split","lastLine","subsequentTokens","subsequentText","contextualMessage","repeat","partial","input","validationError","token","index","tokenRe","decimal","integer","identifier","string","whitespace","comment","other","stringTypes","argumentNameKeywords","nonRegexTerminals","concat","punctuations","tokeniser_Tokeniser","idl","str","lastCharIndex","nextChar","charAt","result","test","attemptTokenMatch","noFlushTrivia","currentTrivia","pop","match","includes","punctuation","startsWith","push","Error","re","lastIndex","exec","tokenise","WebIDLParseError","syntaxError","candidates","probe","super","type_suffix","tokeniser","obj","nullable","consume","error","single_type","typeName","ret","base","type_Type","open","subtype","return_type","type_with_extended_attributes","keyType","keyIdlType","separator","valueType","idlType","close","generic_type","primitive_type","generic","typ","or","union_type","extAttrs","Boolean","union","helpers_unescape","prefix","postfix","filter","default_Default","assign","def","const_value","expression","const_data","negative","ArrayBase","Array","extended_attributes_ExtendedAttributeParameters","secondaryName","list","rhsType","ids","parser","token_Token","listName","identifiers","argument_list","hasRhs","extended_attributes_SimpleExtendedAttribute","params","parse","rhs","arguments","extended_attributes_ExtendedAttributes","argument_Argument","start_position","optional","variadic","default","unconsume","allowDangler","first","items","item","num_type","integer_type","decimal_type","voidToken","enum_EnumValue","enum_Enum","values","termination","includes_Includes","target","mixin","parseByTokens","options","ID","Constant","CallbackFunction","Attribute","special","noInherit","readonly","Operation","regular","static_member","stringifier","IterableLike","secondTypeRequired","secondTypeAllowed","Container","instance","inheritable","allowedMembers","colon","members","ea","mem","args","Interface","callback","Mixin","interface_","opts","Namespace","Dictionary","Field","required","Typedef","definition","tok","res","defs","eof","concrete","definitions","noop","arg","templates","wrap","reference","extendedAttribute","extendedAttributeReference","write","ast","ts","raw","unescaped","context","wrapper","reference_token","name_token","type_body","it","firstToken","ref","extended_attributes","default_","argument","data","make_ext_at","id","eats","container","inh","iterate","iterable_like","parent","table","interface","interface mixin","namespace","operation","body","attribute","dictionary","field","const","typedef","enum","enum-value","v","iterable","legacyiterable","maplike","setlike","callback interface","things","results","thing","dispatch","checkDuplicatedNames","unique","duplicates","dup","checkInterfaceMemberDuplication","interfaces","includesMap","Map","all","include","array","set","getIncludesMap","forEachInterface","opNames","Set","getOperations","op","partials","mixins","ext","additions","forEachExtension","addition","add","existings","has","validate","groupDefinitions","__webpack_exports__"],"mappings":"CAAA,SAAAA,EAAAC,GACA,iBAAAC,SAAA,iBAAAC,OACAA,OAAAD,QAAAD,IACA,mBAAAG,eAAAC,IACAD,OAAA,GAAAH,GACA,iBAAAC,QACAA,QAAA,QAAAD,IAEAD,EAAA,QAAAC,IARA,CASCK,KAAA,WACD,mBCTA,IAAAC,EAAA,GAGA,SAAAC,EAAAC,GAGA,GAAAF,EAAAE,GACA,OAAAF,EAAAE,GAAAP,QAGA,IAAAC,EAAAI,EAAAE,GAAA,CACAC,EAAAD,EACAE,GAAA,EACAT,QAAA,IAUA,OANAU,EAAAH,GAAAI,KAAAV,EAAAD,QAAAC,IAAAD,QAAAM,GAGAL,EAAAQ,GAAA,EAGAR,EAAAD,QA0DA,OArDAM,EAAAM,EAAAF,EAGAJ,EAAAO,EAAAR,EAGAC,EAAAQ,EAAA,SAAAd,EAAAe,EAAAC,GACAV,EAAAW,EAAAjB,EAAAe,IACAG,OAAAC,eAAAnB,EAAAe,EAAA,CAA0CK,YAAA,EAAAC,IAAAL,KAK1CV,EAAAgB,EAAA,SAAAtB,GACA,oBAAAuB,eAAAC,aACAN,OAAAC,eAAAnB,EAAAuB,OAAAC,YAAA,CAAwDC,MAAA,WAExDP,OAAAC,eAAAnB,EAAA,cAAiDyB,OAAA,KAQjDnB,EAAAoB,EAAA,SAAAD,EAAAE,GAEA,GADA,EAAAA,IAAAF,EAAAnB,EAAAmB,IACA,EAAAE,EAAA,OAAAF,EACA,KAAAE,GAAA,iBAAAF,QAAAG,WAAA,OAAAH,EACA,IAAAI,EAAAX,OAAAY,OAAA,MAGA,GAFAxB,EAAAgB,EAAAO,GACAX,OAAAC,eAAAU,EAAA,WAAyCT,YAAA,EAAAK,UACzC,EAAAE,GAAA,iBAAAF,EAAA,QAAAM,KAAAN,EAAAnB,EAAAQ,EAAAe,EAAAE,EAAA,SAAAA,GAAgH,OAAAN,EAAAM,IAAqBC,KAAA,KAAAD,IACrI,OAAAF,GAIAvB,EAAA2B,EAAA,SAAAhC,GACA,IAAAe,EAAAf,KAAA2B,WACA,WAA2B,OAAA3B,EAAA,SAC3B,WAAiC,OAAAA,GAEjC,OADAK,EAAAQ,EAAAE,EAAA,IAAAA,GACAA,GAIAV,EAAAW,EAAA,SAAAiB,EAAAC,GAAsD,OAAAjB,OAAAkB,UAAAC,eAAA1B,KAAAuB,EAAAC,IAGtD7B,EAAAgC,EAAA,GAIAhC,IAAAiC,EAAA,yCClFO,MAAAC,EACPC,aAAAC,OAAeA,EAAAC,WACfzB,OAAA0B,iBAAAxC,KAAA,CACAsC,OAAA,CAAejB,MAAAiB,GACfC,OAAA,CAAelB,MAAAkB,KAIfF,SACA,MAAAI,EAAA,CAAkBC,UAAAC,EAAAhC,UAAAgC,EAAAC,iBAAAD,GAClB,IAAAE,EAAA7C,KACA,KAAA6C,IAAA/B,OAAAkB,WAAA,CACA,MAAAc,EAAAhC,OAAAiC,0BAAAF,GACA,UAAAlB,EAAAN,KAAAP,OAAAkC,QAAAF,IACAzB,EAAAL,YAAAK,EAAAJ,OACAwB,EAAAd,GAAA3B,KAAA2B,IAGAkB,EAAA/B,OAAAmC,eAAAJ,GAEA,OAAAJ,GCRA,SAASS,EAAKZ,EAAAa,EAAAC,EAAAC,EAAAX,GAId,SAAAY,EAAAC,GACA,OAAAA,EAAA,EACAjB,EAAAkB,MAAAL,IAAAI,GACAjB,EAAAkB,MAAAC,KAAAC,IAAAP,EAAAI,EAAA,GAAAJ,GAGA,SAAAQ,EAAAC,GAAAC,SAAiCA,GAAW,IAC5C,MAAAC,EAAAF,EAAAG,IAAAzC,KAAA0C,OAAA1C,EAAAD,OAAA4C,KAAA,IACAC,EAAA5B,EAAAa,GACA,cAAAe,EAAAxB,KACAoB,EAEAD,EACAC,EAAAI,EAAAF,OAEAF,EAAAN,MAAAU,EAAAF,OAAAG,QAGA,MACAC,EACA,QAAA9B,EAAAa,GAAAT,KAAAJ,EAAAa,GAAAiB,KACA9B,EAAA6B,OAAA,EAAA7B,EAAAa,EAAA,GAAAiB,KACA,EAEAC,EArCA,SAAAP,GACA,MAAAQ,EAAAR,EAAAS,MAAA,MACA,OAAAD,IAAAH,OAAA,GAmCAK,CACAb,EAAAL,GAPA,GAOA,CAA2CO,UAAA,KAG3CY,EAAAnB,EAVA,GAWAoB,EAAAf,EAAAc,GAIAE,EAAAN,EAHAK,EAAAH,MAAA,SAGA,MADA,IAAAK,OAAAP,EAAAF,QAAA,KAAAd,GAKA,OACAA,WAAgBX,mBAAsB0B,IAFtChB,OADA,WAAAV,EAAA,sBAC6DU,EAAAyB,QAAA,gBAAoCzB,EAAAV,QAAgBU,EAAAzC,SAAa,QAEzDgE,IACrEP,OACAU,MAAAJ,EACAnC,OAAAkC,GAcO,SAAAM,EAAAzC,EAAA0C,EAAA5B,EAAAC,GACP,OAASH,EAAKZ,EAAA0C,EAAAC,MAAA7B,EAAAC,EAAA,cAAAA,QCpEd,MAAA6B,EAAA,CAGAC,QAAA,sGACAC,QAAA,8CACAC,WAAA,+BACAC,OAAA,WACAC,WAAA,cACAC,QAAA,iDACAC,MAAA,wBAGOC,EAAA,CACP,aACA,YACA,aAGOC,EAAA,CACP,YACA,WACA,QACA,UACA,aACA,OACA,SACA,WACA,UACA,YACA,WACA,UACA,YACA,UACA,WACA,UACA,SACA,SACA,cACA,UACA,gBAGAC,EAAA,CACA,YACA,cACA,WACA,MACA,UACA,UACA,OACA,SACA,QACA,QACA,aACA,iBACA,OACA,QACA,OACA,QACA,WACA,KACA,WACA,SACA,WACA,QACA,OACA,WACA,QACAC,OAAAF,EAAAD,GAEAI,EAAA,CACA,IACA,IACA,IACA,MACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,KA6FO,MAAMC,EAIb1D,YAAA2D,GACAhG,KAAAsC,OA5FA,SAAA2D,GACA,MAAA1D,EAAA,GACA,IAAA2D,EAAA,EACAlC,EAAA,GACAI,EAAA,EACAa,EAAA,EACA,KAAAiB,EAAAD,EAAA9B,QAAA,CACA,MAAAgC,EAAAF,EAAAG,OAAAF,GACA,IAAAG,GAAA,EAQA,GANA,YAAAC,KAAAH,GACAE,EAAAE,EAAA,cAAgDC,eAAA,IAC3C,MAAAL,IACLE,EAAAE,EAAA,WAA6CC,eAAA,MAG7C,IAAAH,EAAA,CACA,MAAAI,EAAAlE,EAAAmE,MAAArF,MACA+C,IAAAqC,EAAAE,MAAA,YAAAxC,OACAH,GAAAyC,EACAxB,GAAA,OACK,oBAAAqB,KAAAH,IAKL,IAHA,KADAE,EAAAE,EAAA,cAEAF,EAAAE,EAAA,aAEA,IAAAF,EAAA,CACAA,EAAAE,EAAA,cACA,MAAAvB,EAAAzC,IAAA4B,OAAA,IACA,IAAAkC,GAAAT,EAAAgB,SAAA5B,EAAA3D,SACA2D,EAAAtC,KAAAsC,EAAA3D,YAGK,MAAA8E,IACLE,EAAAE,EAAA,WAGA,UAAAM,KAAAf,EACA,GAAAG,EAAAa,WAAAD,EAAAX,GAAA,CACA3D,EAAAwE,KAAA,CAAqBrE,KAAAmE,EAAAxF,MAAAwF,EAAA7C,SAAAI,OAAAa,UACrBjB,EAAA,GAEAqC,EADAH,GAAAW,EAAA1C,OAEA,MAQA,IAHA,IAAAkC,IACAA,EAAAE,EAAA,WAEA,IAAAF,EACA,UAAAW,MAAA,gCAEAd,EAAAG,EACApB,GAAA,EAUA,OANA1C,EAAAwE,KAAA,CACArE,KAAA,MACArB,MAAA,GACA2C,WAGAzB,EAOA,SAAAgE,EAAA7D,GAAA8D,cAAoCA,GAAgB,IACpD,MAAAS,EAAA/B,EAAAxC,GACAuE,EAAAC,UAAAhB,EACA,MAAAG,EAAAY,EAAAE,KAAAlB,GACA,OAAAI,GACA9D,EAAAwE,KAAA,CAAmBrE,OAAArB,MAAAgF,EAAA,GAAArC,SAAAI,OAAAa,UACnBuB,IACAxC,EAAA,IAEAiD,EAAAC,YAEA,GASAE,CAAApB,GACAhG,KAAAmD,SAAA,EAMAd,MAAAgB,GACA,UAAAgE,EDlIO,SAAA/E,EAAAa,EAAAC,EAAAC,GACP,OAASH,EAAKZ,EAAAa,EAAAC,EAAAC,EAAA,UCiIiBiE,CAAWtH,KAAAsC,OAAAtC,KAAAmD,SAAAnD,KAAAoD,QAAAC,IAM1ChB,MAAAK,GACA,OAAA1C,KAAAsC,OAAA6B,OAAAnE,KAAAmD,UAAAnD,KAAAsC,OAAAtC,KAAAmD,UAAAT,SAMAL,WAAAkF,GACA,UAAA7E,KAAA6E,EAAA,CACA,IAAAvH,KAAAwH,MAAA9E,GAAA,SACA,MAAAsC,EAAAhF,KAAAsC,OAAAtC,KAAAmD,UAEA,OADAnD,KAAAmD,WACA6B,GAOA3C,UAAAc,GACAnD,KAAAmD,YAIA,MAAAkE,UAAAL,MACA3E,aAAAgB,QAAeA,EAAAe,OAAAU,QAAAvC,WACfkF,MAAApE,GACArD,KAAAW,KAAA,mBACAX,KAAAoE,OACApE,KAAA8E,QACA9E,KAAAuC,UCvLA,SAAAmF,EAAAC,EAAAC,GACA,MAAAC,EAAAF,EAAAG,QAAA,KACAD,IACAD,EAAArF,OAAAsF,YAEAF,EAAAH,MAAA,MAAAG,EAAAI,MAAA,iCAOA,SAAAC,EAAAL,EAAAM,GACA,IAAAC,EApDA,SAAAP,EAAAM,GACA,MAAAE,EAAAR,EAAAG,QAAA,6CACA,IAAAK,EACA,OAEA,MAAAD,EAAA,IAAkBE,EAAI,CAAE9F,OAAAqF,EAAArF,OAAAC,OAAA,CAAoC4F,UAE5D,OADAD,EAAA3F,OAAA8F,KAAAV,EAAAG,QAAA,MAAAH,EAAAI,kCAA0FI,EAAAzF,QAC1FyF,EAAAzF,MACA,eACAiF,EAAAH,MAAA,MAAAG,EAAAI,MAAA,+CACA,MAAAO,EAAsBC,EAAWZ,EAAAM,IAAAN,EAAAI,MAAA,2BACjCG,EAAAI,QAAAvB,KAAAuB,GACA,MAEA,eACA,mBACA,MAAAA,EAAsBE,EAA6Bb,EAAAM,IAAAN,EAAAI,iBAAoDI,EAAAzF,gBACvGwF,EAAAI,QAAAvB,KAAAuB,GACA,MAEA,cACAX,EAAAH,MAAA,MAAAG,EAAAI,MAAA,6CACA,MAAAU,EAAAd,EAAAG,WAA2CpC,IAAWiC,EAAAI,oCAAmDrC,EAAWzB,KAAA,SACpHyE,EAAA,IAA6BN,EAAI,CAAE9F,OAAAqF,EAAArF,OAAAC,OAAA,CAAoC4F,KAAAM,KACvEC,EAAAnG,OAAAoG,UAAAhB,EAAAG,QAAA,MAAAH,EAAAI,MAAA,uCACAW,EAAAhG,KAAAuF,EACA,MAAAW,EAAwBJ,EAA6Bb,EAAAM,IAAAN,EAAAI,MAAA,qCACrDG,EAAAI,QAAAvB,KAAA2B,EAAAE,GACA,OAKA,OAFAV,EAAAW,SAAAlB,EAAAI,oCAAkEI,EAAAzF,QAClEwF,EAAA3F,OAAAuG,MAAAnB,EAAAG,QAAA,MAAAH,EAAAI,uCAAgGI,EAAAzF,QAChGwF,EAmBAa,CAAApB,EAAAM,IAAiDe,EAAcrB,GAC/D,IAAAO,EAAA,CACA,MAAAC,EAAAR,EAAAG,QAAA,gBAAoDpC,GACpD,IAAAyC,EACA,OAEAD,EAAA,IAAcE,EAAI,CAAE9F,OAAAqF,EAAArF,OAAAC,OAAA,CAAoC4F,UACxDR,EAAAH,MAAA,MAAAG,EAAAI,kCAA0EI,EAAA9G,SAQ1E,MANA,YAAA6G,EAAAe,SAAAtB,EAAAH,MAAA,MACAG,EAAAI,MAAA,mCAEAG,EAAAxF,KAAAuF,GAAA,KACAP,EAAAC,EAAAO,GACAA,EAAAL,UAAA,QAAAK,EAAAW,SAAAlB,EAAAI,MAAA,sCACAG,EA+BO,MAAME,UAAahG,EAK1BC,aAAAsF,EAAAM,GACA,OAAAD,EAAAL,EAAAM,IA9BA,SAAAN,EAAAjF,GACA,MAAAH,EAAA,GAEA,GADAA,EAAA8F,KAAAV,EAAAG,QAAA,MACAvF,EAAA8F,KAAA,OACA,MAAAH,EAAA,IAAkBE,EAAI,CAAE9F,OAAAqF,EAAArF,OAAAC,WAExB,IADA2F,EAAAxF,QAAA,OACA,CACA,MAAAwG,EAAgBV,EAA6Bb,MAAAI,MAAA,wDAC7C,QAAAmB,EAAAL,SAAAlB,EAAAI,MAAA,iDACAG,EAAAI,QAAAvB,KAAAmC,GACA,MAAAC,EAAAxB,EAAAG,QAAA,MACA,IAAAqB,EAGA,MAFAD,EAAA3G,OAAAoG,UAAAQ,EASA,OALAjB,EAAAW,QAAA1E,OAAA,GACAwD,EAAAI,MAAA,kEAEAxF,EAAAuG,MAAAnB,EAAAG,QAAA,MAAAH,EAAAI,MAAA,2BACAL,EAAAC,EAAAO,GACAA,EASAkB,CAAAzB,EAAAM,GAGA5F,aAAAC,OAAeA,EAAAC,WACfkF,MAAA,CAAWnF,SAAAC,WACXzB,OAAAC,eAAAf,KAAA,WAA4CqB,MAAA,KAC5CrB,KAAAqJ,SAAA,GAGAJ,cACA,OAAAjJ,KAAAsI,QAAAnE,QAAAnE,KAAAuC,OAAA4F,KACAnI,KAAAuC,OAAA4F,KAAA9G,MAEA,GAEAwG,eACA,OAAAyB,QAAAtJ,KAAAuC,OAAAsF,UAEA0B,YACA,OAAAD,QAAAtJ,KAAAsI,QAAAnE,UAAAnE,KAAAuC,OAAA4F,KAEAU,cACA,GAAA7I,KAAAsI,QAAAnE,OACA,OAAAnE,KAAAsI,QAQA,OAAWkB,EALX,CACAxJ,KAAAuC,OAAAkH,OACAzJ,KAAAuC,OAAA4F,KACAnI,KAAAuC,OAAAmH,SACAC,OAAArI,MAAAyC,IAAAzC,KAAAD,OAAA4C,KAAA,OC3IO,MAAM2F,UAAgBxH,EAI7BC,aAAAsF,GACA,MAAAkC,EAAAlC,EAAAG,QAAA,KACA,IAAA+B,EACA,YAEA,MAAAC,EAAgBC,EAAWpC,MAAAG,QAAA,0BAA0DH,EAAAI,MAAA,wBACrFiC,EAAA,CAAAF,GACA,SAAAA,EAAApH,KAAA,CACA,MAAAoG,EAAAnB,EAAAG,QAAA,MAAAH,EAAAI,MAAA,wCACAiC,EAAAjD,KAAA+B,QACK,SAAAgB,EAAApH,KAAyB,CAC9B,MAAAoG,EAAAnB,EAAAG,QAAA,MAAwCH,EAAAI,MAAA,0CACxCiC,EAAAjD,KAAA+B,GAEA,WAAec,EAAO,CAAEtH,OAAAqF,EAAArF,OAAAC,OAAA,CAAoCsH,UAASG,eAGrE3H,aAAAC,OAAeA,EAAAC,SAAAyH,eACfvC,MAAA,CAAWnF,SAAAC,WACXzB,OAAAC,eAAAf,KAAA,cAA+CqB,MAAA2I,IAG/CtH,WACA,OAAWuH,EAAUjK,KAAAgK,WAAA,IAAAtH,KAErBrB,YACA,OAAW4I,EAAUjK,KAAAgK,WAAA,IAAA3I,MAErB6I,eACA,OAAWD,EAAUjK,KAAAgK,WAAA,IAAAE,UCpCd,MAAAC,UAAAC,MACP/H,aAAAC,OAAeA,EAAAC,WACfkF,QACA3G,OAAA0B,iBAAAxC,KAAA,CACAsC,OAAA,CAAejB,MAAAiB,GACfC,OAAA,CAAelB,MAAAkB,MCDf,MAAM8H,UAAoCjI,EAI1CC,aAAAsF,GACA,MAAApF,EAAA,CAAoBsH,OAAAlC,EAAAG,QAAA,MACpBI,EAAA,IAAoBmC,EAA2B,CAAE/H,OAAAqF,EAAArF,OAAAC,WAejD,OAdAA,EAAAsH,SACAtH,EAAA+H,cAAA3C,EAAAG,QAAA,4CAEAvF,EAAA8F,KAAAV,EAAAG,QAAA,KACAvF,EAAA8F,MACAH,EAAAqC,KAAA,oBAAArC,EAAAsC,QC+FO,SAAA7C,GACP,MAAA8C,EAAAF,EAAA5C,EAAA,CAA+B+C,OAASC,EAAKD,OAAA/C,EAAA,cAAAiD,SAAA,oBAC7CH,EAAAtG,QACAwD,EAAAI,MAAA,uCAEA,OAAA0C,EDlGQI,CAAWlD,GAEXmD,EAAanD,GACrBpF,EAAAuG,MAAAnB,EAAAG,QAAA,MAAAH,EAAAI,MAAA,yDACKG,EAAA6C,SAAAxI,EAAA+H,eACL3C,EAAAI,MAAA,uDAEAG,EAGAsC,cACA,OAAAxK,KAAAuC,OAAAsH,OACA7J,KAAAuC,OAAA+H,cACAtK,KAAAuC,OAAA+H,cAAA5H,KADA,kBADA,MAMA,MAAMsI,UAAgC5I,EAItCC,aAAAsF,GACA,MAAAhH,EAAAgH,EAAAG,QAAA,cACA,GAAAnH,EACA,WAAiBqK,EAAuB,CACxCzI,OAAA,CAAiB5B,QACjBsK,OAAgBZ,EAA2Ba,MAAAvD,KAK3CtF,aAAAC,OAAeA,EAAAC,SAAA0I,WACfxD,MAAA,CAAWnF,SAAAC,WACXzB,OAAAC,eAAAf,KAAA,UAA2CqB,MAAA4J,IAG3CvI,WACA,2BAEA/B,WACA,OAAAX,KAAAuC,OAAA5B,KAAAU,MAEA8J,UACA,MAAWX,QAAA9H,EAAAH,SAAAgI,QAA8BvK,KAAAiL,OACzC,OAAAvI,EAIA,CAAYA,OAAArB,MADZ,oBAAAqB,EAAA6H,EAAAhI,EAAA+H,cAAAjJ,OAFA,KAKA+J,gBACA,MAAAZ,QAAWA,EAAAD,QAAgBvK,KAAAiL,OAC3B,OAAAV,GAAA,oBAAAC,EAGAD,EAFA,IAQO,MAAMc,UAA2BlB,EAIxC9H,aAAAsF,GACA,MAAApF,EAAA,GAEA,GADAA,EAAA8F,KAAAV,EAAAG,QAAA,MACAvF,EAAA8F,KAAA,SACA,MAAAH,EAAA,IAAoBmD,EAAkB,CAAE/I,OAAAqF,EAAArF,OAAAC,WAYxC,OAXA2F,EAAAnB,QAAgBwD,EAAI5C,EAAA,CACpB+C,OAAcM,EAAuBE,MACrCN,SAAA,wBAEArI,EAAAuG,MAAAnB,EAAAG,QAAA,MAAAH,EAAAI,MAAA,kDACAG,EAAA/D,QACAwD,EAAAI,MAAA,qCAEAJ,EAAAH,MAAA,MACAG,EAAAI,MAAA,kEAEAG,GE7FO,MAAMoD,UAAiBlJ,EAI9BC,aAAAsF,GACA,MAAA4D,EAAA5D,EAAAxE,SACAZ,EAAA,GACA2F,EAAA,IAAoBoD,EAAQ,CAAEhJ,OAAAqF,EAAArF,OAAAC,WAI9B,OAHA2F,EAAAmB,SAAmBgC,EAAkBH,MAAAvD,GACrCpF,EAAAiJ,SAAA7D,EAAAG,QAAA,YACAI,EAAAW,QAAkBL,EAA6Bb,EAAA,iBAC/CO,EAAAW,SAGAtG,EAAAiJ,WACAjJ,EAAAkJ,SAAA9D,EAAAG,QAAA,QAEAvF,EAAA5B,KAAAgH,EAAAG,QAAA,gBAAqDnC,GACrDpD,EAAA5B,MAGAuH,EAAAwD,QAAAnJ,EAAAiJ,SAAoC5B,EAAOsB,MAAAvD,GAAA,KAC3CO,GAHAP,EAAAgE,UAAAJ,IAPA5D,EAAAgE,UAAAJ,GAaAC,eACA,QAAAxL,KAAAuC,OAAAiJ,SAEAC,eACA,QAAAzL,KAAAuC,OAAAkJ,SAEA9K,WACA,OAAW6I,EAAQxJ,KAAAuC,OAAA5B,KAAAU,QCpCZ,MAAMsJ,UAAcvI,EAK3BC,cAAAsF,EAAAjF,GACA,WACA,MAAArB,EAAAsG,EAAAG,QAAApF,GACA,GAAArB,EACA,WAAmBsJ,EAAK,CAAErI,OAAAqF,EAAArF,OAAAC,OAAA,CAAoClB,YAK9DA,YACA,OAAArB,KAAAuC,OAAAlB,aFTO,SAASmI,EAAQnE,GACxB,OAAAA,EAAAyB,WAAA,KAAAzB,EAAA7B,MAAA,GAAA6B,EAWO,SAAAkF,EAAA5C,GAAA+C,OAA0BA,EAAAkB,eAAAhB,WAAA,SACjC,MAAAiB,EAAAnB,EAAA/C,GACA,IAAAkE,EACA,SAEAA,EAAAtJ,OAAAoG,UAAAhB,EAAAG,QAAA,KACA,MAAAgE,EAAA,CAAAD,GACA,KAAAA,EAAAtJ,OAAAoG,WAAA,CACA,MAAAoD,EAAArB,EAAA/C,GACA,IAAAoE,EAAA,CACAH,GACAjE,EAAAI,2BAA6C6C,KAE7C,MAIA,GAFAmB,EAAAxJ,OAAAoG,UAAAhB,EAAAG,QAAA,KACAgE,EAAA/E,KAAAgF,IACAA,EAAAxJ,OAAAoG,UAAA,MAEA,OAAAmD,EAMO,SAAA/B,EAAApC,GACP,OAAAA,EAAAG,QAAA,iEAQO,SAAAmC,GAAAvH,KAAqBA,EAAArB,UAC5B,OAAAqB,GACA,WACA,YACA,OAAcA,KAAA,UAAArB,MAAA,SAAAqB,GACd,eACA,gBACA,OAAcA,KAAA,WAAAwH,SAAAxH,EAAAoE,WAAA,MACd,QACA,OAAcpE,KAAA,WAAArB,MAAA,IACd,QACA,OAAcqB,KAAA,cACd,cACA,cACA,OAAcA,KAAA,SAAArB,SACd,aACA,OAAcqB,KAAA,SAAArB,QAAAmC,MAAA,OACd,QACA,OAAcd,SAOP,SAAAsG,EAAArB,GAoBP,MAAArF,OAASA,GAASqF,EAClBqE,EApBA,WACA,MAAAvC,EAAA9B,EAAAG,QAAA,YACAK,EAAAR,EAAAG,QAAA,gBACA,GAAAK,EAAA,CACA,MAAAuB,EAAA/B,EAAAG,QAAA,QACA,WAAiBM,EAAI,CAAE9F,SAAAC,OAAA,CAAkBkH,SAAAtB,OAAAuB,aAEzCD,GAAA9B,EAAAI,MAAA,gCAaAkE,IAVA,WACA,MAAAxC,EAAA9B,EAAAG,QAAA,gBACAK,EAAAR,EAAAG,QAAA,kBACA,GAAAK,EACA,WAAiBC,EAAI,CAAE9F,SAAAC,OAAA,CAAkBkH,SAAAtB,UAEzCsB,GAAA9B,EAAAI,MAAA,8BAIAmE,GACA,GAAAF,EAAA,OAAAA,EACA,MAAA7D,EAAAR,EAAAG,QAAA,0BACA,OAAAK,EACA,IAAeC,EAAI,CAAE9F,SAAAC,OAAA,CAAkB4F,eADvC,EAmBO,SAAA2C,EAAAnD,GACP,OAAA4C,EAAA5C,EAAA,CAA0B+C,OAASY,EAAQJ,MAAAN,SAAA,mBAOpC,SAAApC,EAAAb,EAAAM,GACP,MAAAoB,EAAmBgC,EAAkBH,MAAAvD,GACrCO,EAAcE,EAAI8C,MAAAvD,EAAAM,GAElB,OADAC,MAAAmB,YACAnB,EAOO,SAAAK,EAAAZ,EAAAM,GACP,MAAAiB,EAAcd,EAAI8C,MAAAvD,EAAAM,GAAA,eAClB,GAAAiB,EACA,OAAAA,EAEA,MAAAiD,EAAAxE,EAAAG,QAAA,QACA,GAAAqE,EAAA,CACA,MAAAjE,EAAA,IAAoBE,EAAI,CAAE9F,OAAAqF,EAAArF,OAAAC,OAAA,CAAoC4F,KAAAgE,KAE9D,OADAjE,EAAAxF,KAAA,cACAwF,GGlJA,MAAMkE,UAAkBzB,EAIxBtI,aAAAsF,GACA,MAAAtG,EAAAsG,EAAAG,QAAA,UACA,GAAAzG,EACA,WAAiB+K,EAAS,CAAE9J,OAAAqF,EAAArF,OAAAC,OAAA,CAAoClB,WAIhEqB,WACA,mBAEArB,YACA,OAAAoG,MAAApG,MAAAmC,MAAA,OAIO,MAAM6I,UAAajK,EAI1BC,aAAAsF,GACA,MAAApF,EAAA,GAEA,GADAA,EAAA4F,KAAAR,EAAAG,QAAA,SACAvF,EAAA4F,KACA,OAEA5F,EAAA5B,KAAAgH,EAAAG,QAAA,eAAAH,EAAAI,MAAA,oBACA,MAAAG,EAAAP,EAAAvE,QAAA,IAAwCiJ,EAAI,CAAE/J,OAAAqF,EAAArF,OAAAC,WAe9C,OAdAA,EAAA8F,KAAAV,EAAAG,QAAA,MAAsCH,EAAAI,MAAA,iBACtCG,EAAAoE,OAAiB/B,EAAI5C,EAAA,CACrB+C,OAAc0B,EAASlB,MACvBU,cAAA,EACAhB,SAAA,gBAEAjD,EAAAH,MAAA,WACAG,EAAAI,MAAA,gCAEAxF,EAAAuG,MAAAnB,EAAAG,QAAA,MAAuCH,EAAAI,MAAA,4BACvCG,EAAAoE,OAAAnI,QACAwD,EAAAI,MAAA,oBAEAxF,EAAAgK,YAAA5E,EAAAG,QAAA,MAA6CH,EAAAI,MAAA,2BAC7CG,EAGAxF,WACA,aAEA/B,WACA,OAAW6I,EAAQxJ,KAAAuC,OAAA5B,KAAAU,QCrDZ,MAAMmL,UAAiBpK,EAI9BC,aAAAsF,GACA,MAAA8E,EAAA9E,EAAAG,QAAA,cACA,IAAA2E,EACA,OAEA,MAAAlK,EAAA,CAAoBkK,UAEpB,GADAlK,EAAAqE,SAAAe,EAAAG,QAAA,YACAvF,EAAAqE,SAMA,OAFArE,EAAAmK,MAAA/E,EAAAG,QAAA,eAAAH,EAAAI,MAAA,iCACAxF,EAAAgK,YAAA5E,EAAAG,QAAA,MAA6CH,EAAAI,MAAA,2CAC7C,IAAeyE,EAAQ,CAAElK,OAAAqF,EAAArF,OAAAC,WALzBoF,EAAAgE,UAAAc,EAAAxH,OAQAvC,WACA,iBAEA+J,aACA,OAAWjD,EAAQxJ,KAAAuC,OAAAkK,OAAApL,OAEnBuF,eACA,OAAW4C,EAAQxJ,KAAAuC,OAAAmK,MAAArL,QCdnB,SAAAsL,EAAAhF,EAAAiF,GACA,MAAAtK,EAAAqF,EAAArF,OAEAuK,EAAA,aAEA,SAAA9E,EAAA9B,GACA0B,EAAAI,MAAA9B,GAGA,SAAAuB,EAAA9E,GACA,OAAAiF,EAAAH,MAAA9E,GAGA,SAAAoF,KAAAP,GACA,OAAAI,EAAAG,WAAAP,GAGA,SAAAoE,EAAAxI,GACA,OAAAwE,EAAAgE,UAAAxI,GAGA,MAAA2J,UAAyB1K,EACzBC,eACA,MAAAE,EAAA,GAEA,GADAA,EAAA4F,KAAAL,EAAA,UACAvF,EAAA4F,KACA,OAEA,IAAAU,EAAoBG,EAAcrB,GAClC,IAAAkB,EAAA,CACA,MAAAV,EAAAL,EAAA+E,IAAA9E,EAAA,qBACAc,EAAA,IAAsBT,EAAI,CAAE9F,SAAAC,OAAA,CAAkB4F,UAE9CX,EAAA,MACAO,EAAA,qCAEAc,EAAAnG,KAAA,aACAH,EAAA5B,KAAAmH,EAAA+E,IAAA9E,EAAA,qBACAxF,EAAAsH,OAAA/B,EAAA,MAAAC,EAAA,iCACAxF,EAAAlB,MAAqB0I,EAAWpC,IAAAI,EAAA,sBAChCxF,EAAAgK,YAAAzE,EAAA,MAAqCC,EAAA,sBACrC,MAAAG,EAAA,IAAA4E,EAAA,CAAgCxK,SAAAC,WAEhC,OADA2F,EAAAW,UACAX,EAGAxF,WACA,cAEA/B,WACA,OAAa6I,EAAQxJ,KAAAuC,OAAA5B,KAAAU,OAErBA,YACA,OAAa4I,EAAUjK,KAAAuC,OAAAlB,QAIvB,MAAA0L,UAAiC3K,EACjCC,aAAA8F,GACA,MAAA5F,EAAA,CAAsB4F,QACtBD,EAAA,IAAA6E,EAAA,CAAwCzK,SAAAC,WASxC,OARAA,EAAA5B,KAAAmH,EAAA+E,IAAA9E,EAAA,wBACAJ,EAAAvE,QAAA8E,EACA3F,EAAAsH,OAAA/B,EAAA,MAAAC,EAAA,6BACAG,EAAAW,QAAoBN,EAAWZ,IAAAI,EAAA,uBAC/BxF,EAAA8F,KAAAP,EAAA,MAAAC,EAAA,4BACAG,EAAAkD,UAAsBN,EAAanD,GACnCpF,EAAAuG,MAAAhB,EAAA,MAAAC,EAAA,yBACAxF,EAAAgK,YAAAzE,EAAA,MAAqCC,EAAA,yBACrCG,EAGAxF,WACA,iBAEA/B,WACA,OAAa6I,EAAQxJ,KAAAuC,OAAA5B,KAAAU,QAcrB,MAAA2L,UAA0B5K,EAC1BC,cAAA4K,QAAkBA,EAAAC,aAAA,EAAAC,YAAA,GAA+C,IACjE,MAAA5B,EAAA5D,EAAAxE,SACAZ,EAAA,CAAsB0K,WACtB/E,EAAA,IAAA8E,EAAA,CAAiC1K,SAAAC,WAYjC,GAXA0K,GAAAC,IACA3K,EAAA0K,QAAAnF,EAAA,YAEA,YAAAI,EAAA+E,SAAAzF,EAAA,aACAO,EAAA,4CAEAxF,EAAA4K,SAAArF,EAAA,YACAqF,IAAA5K,EAAA4K,UAAA3F,EAAA,cACAO,EAAA,+CAEAxF,EAAA4F,KAAAL,EAAA,aACAvF,EAAA4F,KAAA,CAKA,OADAD,EAAAW,QAAoBL,EAA6Bb,EAAA,mBAAAI,EAAA,wBACjDG,EAAAW,QAAAI,SACA,eACA,aAAAlB,8BAAyDG,EAAAW,QAAAI,iBAIzD,OAFA1G,EAAA5B,KAAAmH,EAAA+E,EAAA,aAAA9E,EAAA,wBACAxF,EAAAgK,YAAAzE,EAAA,MAAqCC,EAAA,0BACrCG,EAVAyD,EAAAJ,GAaA7I,WACA,kBAEAuK,cACA,OAAAjN,KAAAuC,OAAA0K,QAGAjN,KAAAuC,OAAA0K,QAAA5L,MAFA,GAIA8L,eACA,QAAAnN,KAAAuC,OAAA4K,SAEAxM,WACA,OAAa6I,EAAQxJ,KAAAuC,OAAA5B,KAAAU,QAIrB,MAAA+L,UAA0BhL,EAC1BC,cAAA4K,QAAkBA,EAAAI,WAAmB,IACrC,MAAA9K,EAAA,CAAsB0K,WACtB/E,EAAA,IAAAkF,EAAA,CAAiC9K,SAAAC,WACjC,OAAA0K,GAAA,gBAAAA,EAAA5L,QACAkB,EAAAgK,YAAAzE,EAAA,KACAvF,EAAAgK,cACArE,EAAAkD,UAAA,GACAlD,IAGA+E,GAAAI,IACA9K,EAAA0K,QAAAnF,EAAA,8BAEAI,EAAAW,QAAoBN,EAAWZ,IAAAI,EAAA,uBAC/BxF,EAAA5B,KAAAmH,EAAA+E,GACAtK,EAAA8F,KAAAP,EAAA,MAAAC,EAAA,qBACAG,EAAAkD,UAAsBN,EAAanD,GACnCpF,EAAAuG,MAAAhB,EAAA,MAAAC,EAAA,0BACAxF,EAAAgK,YAAAzE,EAAA,MAAqCC,EAAA,0BACrCG,GAGAxF,WACA,kBAEA/B,WACA,MAAAA,KAAaA,GAAOX,KAAAuC,OACpB,OAAA5B,EAGa6I,EAAQ7I,EAAAU,OAFrB,GAIA4L,cACA,OAAAjN,KAAAuC,OAAA0K,QAGAjN,KAAAuC,OAAA0K,QAAA5L,MAFA,IAMA,SAAAiM,IACA,MAAAL,EAAAnF,EAAA,UACA,GAAAmF,EAIA,OAHAD,EAAA9B,MAAA,CAAoC+B,aACpCG,EAAAlC,MAAA,CAAuB+B,aACvBlF,EAAA,4BAIA,SAAAwF,IACA,MAAAN,EAAAnF,EAAA,eACA,GAAAmF,EAIA,OAHAD,EAAA9B,MAAA,CAAoC+B,aACpCG,EAAAlC,MAAA,CAAuB+B,aACvBlF,EAAA,4BAIA,MAAAyF,UAA6BpL,EAC7BC,eACA,MAAAkJ,EAAA5D,EAAAxE,SACAZ,EAAA,GACA2F,EAAA,IAAAsF,EAAA,CAAoClL,SAAAC,WAKpC,GAJAA,EAAA4K,SAAArF,EAAA,YACAvF,EAAA4F,KAAA5F,EAAA4K,SACArF,EAAA,qBACAA,EAAA,iCACAvF,EAAA4F,KAEA,YADAwD,EAAAJ,GAIA,MAAA7I,KAAaA,GAAOwF,EACpBuF,EAAA,YAAA/K,EACAgL,EAAAD,GAAA,aAAA/K,EAEAH,EAAA8F,KAAAP,EAAA,MAAAC,mBAA2DrF,iBAC3D,MAAAmJ,EAAoBrD,EAA6Bb,IAAAI,mBAAsCrF,iBAavF,OAZAwF,EAAAW,QAAA,CAAAgD,GACA6B,IACA7B,EAAAtJ,OAAAoG,UAAAb,EAAA,KACA+D,EAAAtJ,OAAAoG,UACAT,EAAAW,QAAA9B,KAA2ByB,EAA6Bb,IAExD8F,GACA1F,qCAAmDrF,kBAEnDH,EAAAuG,MAAAhB,EAAA,MAAAC,kBAA2DrF,iBAC3DH,EAAAgK,YAAAzE,EAAA,MAAqCC,6BAAuCrF,iBAE5EwF,EAGAxF,WACA,OAAA1C,KAAAuC,OAAA4F,KAAA9G,MAEA8L,eACA,QAAAnN,KAAAuC,OAAA4K,UAaA,MAAAQ,UAA0BvL,EAC1BC,aAAAuL,GAAAlL,KAA4BA,EAAAmL,cAAAC,mBAC5B,MAAAvL,OAAaA,GAASqL,EAQtB,IAPArL,EAAA5B,KAAAmH,EAAA+E,IAAA9E,EAAA,yBACAJ,EAAAvE,QAAAwK,EACAC,GACA/M,OAAA+I,OAAAtH,EAfA,WACA,MAAAwL,EAAAjG,EAAA,KACA,OAAAiG,EAIA,CAAYA,QAAAnL,YADZkF,EAAA+E,IAAA9E,EAAA,2BAFA,GAYAnF,IAEAL,EAAA8F,KAAAP,EAAA,MAA8BC,cAAwBrF,KACtDkL,EAAAI,QAAA,KACA,CAEA,GADAzL,EAAAuG,MAAAhB,EAAA,KACAvF,EAAAuG,MAEA,OADAvG,EAAAgK,YAAAzE,EAAA,MAAyCC,6BAAuCrF,KAChFkL,EAEA,MAAAK,EAAmB5C,EAAkBH,MAAAvD,GACrC,IAAAuG,EACA,UAAAxD,KAAAyD,KAAAL,EAEA,GADAI,EAAAxD,KAAAyD,GAEA,MAGAD,GACAnG,EAAA,kBAEAmG,EAAA7E,SAAA4E,EACAL,EAAAI,QAAAjH,KAAAmH,IAIArJ,cACA,QAAA7E,KAAAuC,OAAAsC,QAEAlE,WACA,OAAa6I,EAAQxJ,KAAAuC,OAAA5B,KAAAU,OAErBuB,kBACA,OAAA5C,KAAAuC,OAAAK,YAGa4G,EAAQxJ,KAAAuC,OAAAK,YAAAvB,OAFrB,MAMA,MAAA+M,UAAAT,EACAtL,aAAA8F,GAAAkG,SAAwBA,EAAA,KAAAxJ,UAAA,MAAkC,IAC1D,MAAAtC,EAAA,CAAsB8L,WAAAxJ,UAAAsD,QACtB,OAAAwF,EAAAzC,MAAA,IAAAkD,EAAA,CAA4C9L,SAAAC,WAAiB,CAC7DG,KAAA,YACAmL,aAAAhJ,EACAiJ,eAAA,CACA,CAAAhB,EAAA5B,OACA,CAAAoC,GACA,CAAAC,GACA,CAAAC,EAAAtC,OACA,CAAA8B,EAAA9B,OACA,CAAAkC,EAAAlC,UAKAxI,WACA,OAAA1C,KAAAuC,OAAA8L,SACA,qBAEA,aAIA,MAAAC,UAAAX,EACAtL,aAAA8F,GAAAtD,QAAwBA,GAAU,IAClC,MAAAtC,EAAA,CAAsBsC,UAAAsD,QAEtB,GADA5F,EAAAmK,MAAA5E,EAAA,SACAvF,EAAAmK,MAGA,OAAAiB,EAAAzC,MAAA,IAAAoD,EAAA,CAAwChM,SAAAC,WAAiB,CACzDG,KAAA,kBACAoL,eAAA,CACA,CAAAhB,EAAA5B,OACA,CAAAqC,GACA,CAAAP,EAAA9B,MAAA,CAA6BgC,WAAA,IAC7B,CAAAE,EAAAlC,MAAA,CAA6BmC,SAAA,OAK7B3K,WACA,yBAIA,SAAA6L,EAAAC,GACA,MAAArG,EAAAL,EAAA,aACA,GAAAK,EAIA,OAHAmG,EAAApD,MAAA/C,EAAAqG,IACAJ,EAAAlD,MAAA/C,EAAAqG,IACAzG,EAAA,gCAIA,MAAA0G,UAAAd,EACAtL,cAAAwC,QAAkBA,GAAU,IAC5B,MAAAtC,EAAA,CAAsBsC,WAEtB,GADAtC,EAAA4F,KAAAL,EAAA,aACAvF,EAAA4F,KAGA,OAAAwF,EAAAzC,MAAA,IAAAuD,EAAA,CAA4CnM,SAAAC,WAAiB,CAC7DG,KAAA,YACAoL,eAAA,CACA,CAAAd,EAAA9B,MAAA,CAA6BgC,WAAA,EAAAC,UAAA,IAC7B,CAAAC,EAAAlC,MAAA,CAA6BmC,SAAA,OAK7B3K,WACA,mBAaA,MAAAgM,UAAAf,EACAtL,cAAAwC,QAAkBA,GAAU,IAC5B,MAAAtC,EAAA,CAAsBsC,WAEtB,GADAtC,EAAA4F,KAAAL,EAAA,cACAvF,EAAA4F,KAGA,OAAAwF,EAAAzC,MAAA,IAAAwD,EAAA,CAA6CpM,SAAAC,WAAiB,CAC9DG,KAAA,aACAmL,aAAAhJ,EACAiJ,eAAA,CACA,CAAAa,EAAAzD,UAKAxI,WACA,oBAIA,MAAAiM,UAAsBvM,EACtBC,eACA,MAAAE,EAAA,GACA2F,EAAA,IAAAyG,EAAA,CAA6BrM,SAAAC,WAQ7B,OAPA2F,EAAAmB,SAAqBgC,EAAkBH,MAAAvD,GACvCpF,EAAAqM,SAAA9G,EAAA,YACAI,EAAAW,QAAoBL,EAA6Bb,EAAA,oBAAAI,EAAA,iCACjDxF,EAAA5B,KAAAmH,EAAA+E,IAAA9E,EAAA,iCACAG,EAAAwD,QAAoB9B,EAAOsB,MAAAvD,GAC3BpF,EAAAqM,UAAA1G,EAAAwD,SAAA3D,EAAA,2CACAxF,EAAAgK,YAAAzE,EAAA,MAAqCC,EAAA,kCACrCG,EAGAxF,WACA,cAEA/B,WACA,OAAa6I,EAAQxJ,KAAAuC,OAAA5B,KAAAU,OAErBuN,eACA,QAAA5O,KAAAuC,OAAAqM,UAIA,MAAAC,UAAwBzM,EACxBC,eACA,MAAAE,EAAA,GACA2F,EAAA,IAAA2G,EAAA,CAA+BvM,SAAAC,WAE/B,GADAA,EAAA4F,KAAAL,EAAA,WACAvF,EAAA4F,KAOA,OAJAD,EAAAW,QAAoBL,EAA6Bb,EAAA,iBAAAI,EAAA,sBACjDxF,EAAA5B,KAAAmH,EAAA+E,IAAA9E,EAAA,sBACAJ,EAAAvE,QAAA8E,EACA3F,EAAAgK,YAAAzE,EAAA,MAAqCC,EAAA,wBACrCG,EAGAxF,WACA,gBAEA/B,WACA,OAAa6I,EAAQxJ,KAAAuC,OAAA5B,KAAAU,QAIrB,SAAAyN,IACA,OAnXA,WACA,MAAAT,EAAAvG,EAAA,YACA,IAAAuG,EAAA,OACA,MAAAU,EAAAjH,EAAA,aACA,OAAAiH,EACAX,EAAAlD,MAAA6D,EAAA,CAAmCV,aAEnCtB,EAAA7B,MAAAmD,GA4WAA,IACAE,KAhFA,WACA,MAAA1J,EAAAiD,EAAA,WACA,GAAAjD,EACA,OAAA6J,EAAAxD,MAAA,CAA6BrG,aAC7B0J,EAAA,CAAkB1J,aAClB4J,EAAAvD,MAAA,CAAuBrG,aACvBkD,EAAA,qCA2EAlD,IACA6J,EAAAxD,SACMmB,EAAInB,MAAAvD,IACVkH,EAAA3D,SACMsB,EAAQtB,MAAAvD,IACd8G,EAAAvD,QAsBA,MAAA8D,EAnBA,WACA,IAAA1M,EAAA6B,OAAA,SACA,MAAA8K,EAAA,GACA,QACA,MAAAhB,EAAiB5C,EAAkBH,MAAAvD,GACnCmC,EAAAgF,IACA,IAAAhF,EAAA,CACAmE,EAAA9J,QAAA4D,EAAA,6BACA,MAEA+B,EAAAT,SAAA4E,EACAgB,EAAAlI,KAAA+C,GAEA,MAAAoF,EAAApH,EAAA,OAIA,OAHA8E,EAAAuC,UACAF,EAAAlI,KAAAmI,GAEAD,EAEAG,GAEA,OADAzH,EAAAxE,SAAAb,EAAA6B,QAAA4D,EAAA,uBACAiH,EAGO,SAAA9D,EAAAjF,EAAA2G,EAAA,IAEP,OAAAD,EADA,IAAwB5G,EAASE,GACjC2G,GCrfA,SAAAyC,EAAAC,GACA,OAAAA,EAGA,MAAAC,EAAA,CACAC,KAAA1D,KAAA7H,KAAA,IACAD,OAAAqL,EACA1O,KAAA0O,EACAI,UAAAJ,EACA3M,KAAA2M,EACApG,QAAAoG,EACAzM,YAAAyM,EACAP,WAAAO,EACAK,kBAAAL,EACAM,2BAAAN,GAGO,SAAAO,EAAAC,GAAqBN,UAAAO,EAAAP,GAA4B,IAGxD,SAAAE,EAAAM,GAAAC,UAA2BA,EAAAC,YAI3B,OAHAD,IACAA,EAAAD,EAAAjJ,WAAA,KAAAiJ,EAAAvM,MAAA,GAAAuM,GAEAD,EAAAL,UAAAM,EAAAC,EAAAC,GAGA,SAAAjL,EAAA1D,EAAA4O,EAAAb,KAAAlB,GACA,IAAA7M,EACA,SAEA,MAAAD,EAAA6O,EAAA5O,EAAAD,SAAA8M,GACA,OAAA2B,EAAAN,KAAA,CAAAM,EAAA9L,OAAA1C,EAAA0C,QAAA3C,IAGA,SAAA8O,EAAA7O,EAAA2O,GACA,OAAAjL,EAAA1D,EAAAmO,EAAA,CAAgCQ,YAGhC,SAAAG,EAAA9O,EAAAgO,GACA,OAAAtK,EAAA1D,EAAAwO,EAAAnP,KAAA2O,GAGA,SAAAe,EAAAC,GACA,GAAAA,EAAA/G,OAAA+G,EAAArH,QACA,OAAA6G,EAAAN,KAAA,CACAxK,EAAAsL,EAAA/N,OAAA4F,KAAA2H,EAAA7G,SACAjE,EAAAsL,EAAA/N,OAAA8F,SACAiI,EAAAhI,QAAAvE,IAAArB,GACAsC,EAAAsL,EAAA/N,OAAAuG,SAGA,MAAAyH,EAAAD,EAAA/N,OAAAkH,QAAA6G,EAAA/N,OAAA4F,KACAsB,EAAA6G,EAAA/N,OAAAkH,OAAA,CACA6G,EAAA/N,OAAAkH,OAAApI,MACAyO,EAAA9L,OAAAsM,EAAA/N,OAAA4F,KAAAnE,SACA,GACAwM,EAAAf,EAAAK,EAAAN,KAAA,IACA/F,EACA6G,EAAA/N,OAAA4F,KAAA9G,MACA2D,EAAAsL,EAAA/N,OAAAmH,WACA,CAASsG,UAAAM,EAAAzH,QAAAoH,QAAAK,IACT,OAAAR,EAAAN,KAAA,CAAAM,EAAA9L,OAAAuM,EAAAvM,QAAAwM,IAEA,SAAA9N,EAAA4N,GACA,OAAAR,EAAAN,KAAA,CACAiB,EAAAH,EAAAjH,UACAgH,EAAAC,GACAtL,EAAAsL,EAAA/N,OAAAsF,UACA7C,EAAAsL,EAAA/N,OAAAoG,aAGA,SAAA+H,EAAA5G,GACA,OAAAA,EAGAgG,EAAAN,KAAA,CACAxK,EAAA8E,EAAAvH,OAAAsH,WACAC,EAAAE,WAAAjG,IAAAzC,GAAA0D,EAAA1D,MAJA,GAOA,SAAAqP,EAAArB,GACA,OAAAQ,EAAAN,KAAA,CACAiB,EAAAnB,EAAAjG,UACArE,EAAAsK,EAAA/M,OAAAiJ,UACAsE,EAAApN,OAAA4M,EAAAzG,UACA7D,EAAAsK,EAAA/M,OAAAkJ,UACA2E,EAAAd,EAAA/M,OAAA5B,KAAA,CAAmCiQ,KAAAtB,IACnCoB,EAAApB,EAAA5D,SACA1G,EAAAsK,EAAA/M,OAAAoG,aASA,SAAAkI,EAAAP,GACA,MAAA9F,QAAWA,GAAU8F,EAAArF,OACrB,OAAA6E,EAAAN,KAAA,CACAM,EAAA9L,OAAAsM,EAAA/N,OAAA5B,KAAAqD,QACA8L,EAAAJ,kBAAAI,EAAAN,KAAA,CACAM,EAAAH,2BAAAW,EAAA3P,MACAqE,EAAAsL,EAAArF,OAAA1I,OAAAsH,QACAsG,EAAAG,EAAArF,OAAA1I,OAAA+H,cAAAgG,GACAtL,EAAAsL,EAAArF,OAAA1I,OAAA8F,SACAiI,EAAArF,OAAAV,KACA+F,EAAArF,OAAAV,KAAAxG,IACA,oBAAAyG,EAAAsG,IAjBA,SAAAA,EAAAb,GACA,OAAAH,EAAAN,KAAA,CACAW,EAAAW,EAAAvO,OAAAlB,MAAA4O,GACAjL,EAAA8L,EAAAvO,OAAAoG,cAcAtD,CAAAyL,EAAAR,GAAAK,GAFA,GAIA3L,EAAAsL,EAAArF,OAAA1I,OAAAuG,UAEA9D,EAAAsL,EAAA/N,OAAAoG,aAGA,SAAA8H,EAAAM,GACA,OAAAA,EAAA5M,OACA2L,EAAAN,KAAA,CACAxK,EAAA+L,EAAAxO,OAAA8F,SACA0I,EAAAhN,IAAA8M,GACA7L,EAAA+L,EAAAxO,OAAAuG,SAJA,GA+CA,SAAAkI,EAAAV,GACA,OAAAR,EAAAhB,WAAAgB,EAAAN,KAAA,CACAiB,EAAAH,EAAAjH,UACArE,EAAAsL,EAAA/N,OAAA8L,UACArJ,EAAAsL,EAAA/N,OAAAsC,SACAG,EAAAsL,EAAA/N,OAAA4F,MACAnD,EAAAsL,EAAA/N,OAAAmK,OACA0D,EAAAE,EAAA/N,OAAA5B,KAAA,CAAkCiQ,KAAAN,KAlBlCW,EAmBAX,EAlBAW,EAAA1O,OAAAK,YAGAkN,EAAAN,KAAA,CACAxK,EAAAiM,EAAA1O,OAAAwL,OACA+B,EAAA9L,OAAAiN,EAAA1O,OAAAK,YAAAoB,QACA8L,EAAAlN,YAAA6M,EAAAwB,EAAA1O,OAAAK,YAAAvB,MAAA,CAA8D4O,QAAAgB,OAL9D,IAkBAjM,EAAAsL,EAAA/N,OAAA8F,MACA6I,EAAAZ,EAAAtC,QAAAsC,GACAtL,EAAAsL,EAAA/N,OAAAuG,OACA9D,EAAAsL,EAAA/N,OAAAgK,eACA,CAASqE,KAAAN,IAxBT,IAAAW,EAoGA,SAAAE,EAAAb,EAAAc,GACA,OAAAtB,EAAAhB,WAAAgB,EAAAN,KAAA,CACAiB,EAAAH,EAAAjH,UACArE,EAAAsL,EAAA/N,OAAA4K,UACAnI,EAAAsL,EAAA/N,OAAA4F,KAAA2H,EAAA7G,SACAjE,EAAAsL,EAAA/N,OAAA8F,MACAyH,EAAAN,KAAAc,EAAAzH,QAAA9E,IAAArB,IACAsC,EAAAsL,EAAA/N,OAAAuG,OACA9D,EAAAsL,EAAA/N,OAAAgK,eACA,CAASqE,KAAAN,EAAAc,WApPTtB,EAAAhP,OAAA+I,OAAA,GAAuB0F,EAAAO,GA0PvB,MAAAuB,EAAA,CACAC,UAAAN,EACAO,kBAAAP,EACAQ,UAAAR,EACAS,UAnJA,SAAAnB,EAAAc,GACA,MAAAM,EAAApB,EAAAzH,QAAA,CACAiH,EAAApN,OAAA4N,EAAAzH,UACAuH,EAAAE,EAAA/N,OAAA5B,KAAA,CAAkCiQ,KAAAN,EAAAc,WAClCpM,EAAAsL,EAAA/N,OAAA8F,MACAyH,EAAAN,KAAAc,EAAAlF,UAAArH,IAAA4M,IACA3L,EAAAsL,EAAA/N,OAAAuG,QACA,GACA,OAAAgH,EAAAhB,WAAAgB,EAAAN,KAAA,CACAiB,EAAAH,EAAAjH,UACArE,EAAAsL,EAAA/N,OAAA0K,YACAyE,EACA1M,EAAAsL,EAAA/N,OAAAgK,eACA,CAASqE,KAAAN,EAAAc,YAuITO,UApIA,SAAArB,EAAAc,GACA,OAAAtB,EAAAhB,WAAAgB,EAAAN,KAAA,CACAiB,EAAAH,EAAAjH,UACArE,EAAAsL,EAAA/N,OAAA0K,SACAjI,EAAAsL,EAAA/N,OAAA4K,UACAnI,EAAAsL,EAAA/N,OAAA4F,MACA2H,EAAApN,OAAA4N,EAAAzH,UACAuH,EAAAE,EAAA/N,OAAA5B,KAAA,CAAkCiQ,KAAAN,EAAAc,WAClCpM,EAAAsL,EAAA/N,OAAAgK,eACA,CAASqE,KAAAN,EAAAc,YA4HTQ,WAAAZ,EACAa,MA/FA,SAAAvB,EAAAc,GACA,OAAAtB,EAAAhB,WAAAgB,EAAAN,KAAA,CACAiB,EAAAH,EAAAjH,UACArE,EAAAsL,EAAA/N,OAAAqM,UACAkB,EAAApN,OAAA4N,EAAAzH,UACAuH,EAAAE,EAAA/N,OAAA5B,KAAA,CAAkCiQ,KAAAN,EAAAc,WAClCV,EAAAJ,EAAA5E,SACA1G,EAAAsL,EAAA/N,OAAAgK,eACA,CAASqE,KAAAN,EAAAc,YAwFTU,MAtFA,SAAAxB,EAAAc,GACA,OAAAtB,EAAAhB,WAAAgB,EAAAN,KAAA,CACAiB,EAAAH,EAAAjH,UACArE,EAAAsL,EAAA/N,OAAA4F,MACA2H,EAAApN,OAAA4N,EAAAzH,UACAuH,EAAAE,EAAA/N,OAAA5B,KAAA,CAAkCiQ,KAAAN,EAAAc,WAClCpM,EAAAsL,EAAA/N,OAAAsH,QACA7E,EAAAsL,EAAA/N,OAAAlB,OACA2D,EAAAsL,EAAA/N,OAAAgK,eACA,CAASqE,KAAAN,EAAAc,YA8ETW,QA5EA,SAAAzB,GACA,OAAAR,EAAAhB,WAAAgB,EAAAN,KAAA,CACAiB,EAAAH,EAAAjH,UACArE,EAAAsL,EAAA/N,OAAA4F,MACA2H,EAAApN,OAAA4N,EAAAzH,UACAuH,EAAAE,EAAA/N,OAAA5B,KAAA,CAAkCiQ,KAAAN,IAClCtL,EAAAsL,EAAA/N,OAAAgK,eACA,CAASqE,KAAAN,KAsET1J,SApEA,SAAA0J,GACA,OAAAR,EAAAhB,WAAAgB,EAAAN,KAAA,CACAiB,EAAAH,EAAAjH,UACA8G,EAAAG,EAAA/N,OAAAkK,OAAA6D,GACAtL,EAAAsL,EAAA/N,OAAAqE,UACAuJ,EAAAG,EAAA/N,OAAAmK,MAAA4D,GACAtL,EAAAsL,EAAA/N,OAAAgK,eACA,CAASqE,KAAAN,KA8DTjC,SA5DA,SAAAiC,GACA,OAAAR,EAAAhB,WAAAgB,EAAAN,KAAA,CACAiB,EAAAH,EAAAjH,UACArE,EAAAsL,EAAA/N,OAAA4F,MACAiI,EAAAE,EAAA/N,OAAA5B,KAAA,CAAkCiQ,KAAAN,IAClCtL,EAAAsL,EAAA/N,OAAAsH,QACAiG,EAAApN,OAAA4N,EAAAzH,UACA7D,EAAAsL,EAAA/N,OAAA8F,SACAiI,EAAAlF,UAAArH,IAAA4M,GACA3L,EAAAsL,EAAA/N,OAAAuG,OACA9D,EAAAsL,EAAA/N,OAAAgK,eACA,CAASqE,KAAAN,KAkDT0B,KAhDA,SAAA1B,GACA,OAAAR,EAAAhB,WAAAgB,EAAAN,KAAA,CACAiB,EAAAH,EAAAjH,UACArE,EAAAsL,EAAA/N,OAAA4F,MACAiI,EAAAE,EAAA/N,OAAA5B,KAAA,CAAkCiQ,KAAAN,IAClCtL,EAAAsL,EAAA/N,OAAA8F,MACA6I,EAAAZ,EAAAhE,OAAAgE,GACAtL,EAAAsL,EAAA/N,OAAAuG,OACA9D,EAAAsL,EAAA/N,OAAAgK,eACA,CAASqE,KAAAN,KAwCT2B,aAtCA,SAAAC,EAAAd,GACA,OAAAtB,EAAAN,KAAA,CACAM,EAAA9L,OAAAkO,EAAA3P,OAAAlB,MAAA2C,QACA8L,EAAAhB,WACAgB,EAAAN,KAAA,KAAAM,EAAAnP,KAAAuR,EAAA7Q,MAAA,CAAwCuP,KAAAsB,EAAAd,WAAkB,MAC1D,CAASR,KAAAsB,EAAAd,WAETpM,EAAAkN,EAAA3P,OAAAoG,cAgCAwJ,SAAAhB,EACAiB,eAAAjB,EACAkB,QAAAlB,EACAmB,QAAAnB,EACAoB,qBAAAvB,EACA9B,IAvBA,SAAAoB,GACA,OAAAR,EAAA9L,OAAAsM,EAAAtM,UA+BA,SAAAkN,EAAAsB,EAAApB,GACA,IAAAoB,EAAA,OACA,MAAAC,EAAAD,EAAAzO,IAAA2O,IATA,SAAApC,EAAAc,GAEA,IADAC,EAAAf,EAAA5N,MAEA,UAAAsE,eAA+BsJ,EAAA5N,wBAE/B,OAAA2O,EAAAf,EAAA5N,MAAA4N,EAAAc,IAIAuB,CAAAD,EAAAtB,IACA,OAAAtB,EAAAN,KAAAiD,GAEA,OAAAvB,EAAArB,GCjRA,SAAA+C,GAAAC,OAAgCA,EAAAC,eAChC,UAAAC,KAAAD,EAAA,CACA,MAAAnS,KAAWA,GAAOoS,EAClB1P,eAAiC1C,eAAkBkS,EAAA5R,IAAAN,GAAA+B,+BACzCqC,EAAKgO,EAAAzQ,OAAAyQ,EAAAxQ,OAAA5B,KAAAoS,EAAA1P,IAIf,SAAA2P,EAAA/D,GACA,MAAAgE,EAAA,IAAAhE,EAAA4D,OAAAvG,UAAA3C,OAAAG,GAAA,cAAAA,EAAApH,MACAwQ,EAkCA,WACA,MAAAnP,EAAA,IAAAoP,IACAvM,EAAAqI,EAAAmE,IAAAzJ,OAAAG,GAAA,aAAAA,EAAApH,MACA,UAAA2Q,KAAAzM,EAAA,CACA,MAAA0M,EAAAvP,EAAA9C,IAAAoS,EAAA5G,QACAC,EAAAuC,EAAA4D,OAAA5R,IAAAoS,EAAAzM,UACA8F,IAGA4G,EACAA,EAAAvM,KAAA2F,GAEA3I,EAAAwP,IAAAF,EAAA5G,OAAA,CAAAC,KAGA,OAAA3I,EAjDAyP,GAEA,UAAApT,KAAA6S,QACAQ,EAAArT,GAGA,SAAAqT,EAAArT,GACA,MAAAsT,EAAA,IAAAC,IAAAC,EAAAxT,GAAA2D,IAAA8P,KAAAlT,OACAmT,EAAA7E,EAAA6E,SAAA7S,IAAAb,EAAAO,OAAA,GACAoT,EAAAb,EAAAjS,IAAAb,EAAAO,OAAA,GACA,UAAAqT,IAAA,IAAAF,KAAAC,GAAA,CACA,MAAAE,EAAAL,EAAAI,SACAE,EAAAD,EAAAP,EAAAM,EAAA5T,GACA,UAAA+T,KAAAF,EACAP,EAAAU,IAAAD,EAAAxT,OAKA,SAAAuT,EAAAD,EAAAI,EAAAL,EAAA7L,GACA,UAAAgM,KAAAF,EAAA,CACA,MAAAtT,KAAaA,GAAOwT,EACpB,GAAAxT,GAAA0T,EAAAC,IAAA3T,GAAA,CACA,MAAA0C,oBAA0C1C,uDAA0DwH,EAAAxH,6CACtFoE,EAAKiP,EAAA1R,OAAA6R,EAAA5R,OAAA5B,KAAAqT,EAAA3Q,KAKnB,SAAAuQ,EAAAxT,GACA,OAAAA,EAAA4N,QACArE,OAAA,EAAgBjH,UAAK,cAAAA,IAsBd,SAAA6R,EAAA1E,GACP,MAAAZ,EA1FA,SAAAmE,GACA,MAAAP,EAAA,IAAAM,IACAL,EAAA,IAAAa,IACAG,EAAA,IAAAX,IACA,UAAArJ,KAAAsJ,EACA,GAAAtJ,EAAAjF,QAAA,CACA,MAAAyO,EAAAQ,EAAA7S,IAAA6I,EAAAnJ,MACA2S,EACAA,EAAAvM,KAAA+C,GAEAgK,EAAAP,IAAAzJ,EAAAnJ,KAAA,CAAAmJ,SAIAA,EAAAnJ,OAGAkS,EAAAyB,IAAAxK,EAAAnJ,MAGAmS,EAAAsB,IAAAtK,GAFA+I,EAAAU,IAAAzJ,EAAAnJ,KAAAmJ,IAKA,OAAUsJ,MAAAP,SAAAiB,WAAAhB,cAmEV0B,CAAA3E,GACA,UACA+C,EAAA3D,MACA+D,EAAA/D,ICjGA/O,EAAAQ,EAAA+T,EAAA,0BAAAvJ,IAAAhL,EAAAQ,EAAA+T,EAAA,0BAAA7E,IAAA1P,EAAAQ,EAAA+T,EAAA,6BAAAF","file":"webidl2.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"WebIDL2\"] = factory();\n\telse\n\t\troot[\"WebIDL2\"] = factory();\n})(this, function() {\nreturn "," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 0);\n","export class Base {\r\n  constructor({ source, tokens }) {\r\n    Object.defineProperties(this, {\r\n      source: { value: source },\r\n      tokens: { value: tokens }\r\n    });\r\n  }\r\n\r\n  toJSON() {\r\n    const json = { type: undefined, name: undefined, inheritance: undefined };\r\n    let proto = this;\r\n    while (proto !== Object.prototype) {\r\n      const descMap = Object.getOwnPropertyDescriptors(proto);\r\n      for (const [key, value] of Object.entries(descMap)) {\r\n        if (value.enumerable || value.get) {\r\n          json[key] = this[key];\r\n        }\r\n      }\r\n      proto = Object.getPrototypeOf(proto);\r\n    }\r\n    return json;\r\n  }\r\n}\r\n","/**\r\n * @param {string} text\r\n */\r\nfunction lastLine(text) {\r\n  const splitted = text.split(\"\\n\");\r\n  return splitted[splitted.length - 1];\r\n}\r\n\r\n/**\r\n * @param {string} message error message\r\n * @param {\"Syntax\" | \"Validation\"} type error type\r\n */\r\nfunction error(source, position, current, message, type) {\r\n  /**\r\n   * @param {number} count\r\n   */\r\n  function sliceTokens(count) {\r\n    return count > 0 ?\r\n      source.slice(position, position + count) :\r\n      source.slice(Math.max(position + count, 0), position);\r\n  }\r\n\r\n  function tokensToText(inputs, { precedes } = {}) {\r\n    const text = inputs.map(t => t.trivia + t.value).join(\"\");\r\n    const nextToken = source[position];\r\n    if (nextToken.type === \"eof\") {\r\n      return text;\r\n    }\r\n    if (precedes) {\r\n      return text + nextToken.trivia;\r\n    }\r\n    return text.slice(nextToken.trivia.length);\r\n  }\r\n\r\n  const maxTokens = 5; // arbitrary but works well enough\r\n  const line =\r\n    source[position].type !== \"eof\" ? source[position].line :\r\n    source.length > 1 ? source[position - 1].line :\r\n    1;\r\n\r\n  const precedingLine = lastLine(\r\n    tokensToText(sliceTokens(-maxTokens), { precedes: true })\r\n  );\r\n\r\n  const subsequentTokens = sliceTokens(maxTokens);\r\n  const subsequentText = tokensToText(subsequentTokens);\r\n  const sobsequentLine = subsequentText.split(\"\\n\")[0];\r\n\r\n  const spaced = \" \".repeat(precedingLine.length) + \"^ \" + message;\r\n  const contextualMessage = precedingLine + sobsequentLine + \"\\n\" + spaced;\r\n\r\n  const contextType = type === \"Syntax\" ? \"since\" : \"inside\";\r\n  const grammaticalContext = current ? `, ${contextType} \\`${current.partial ? \"partial \" : \"\"}${current.type} ${current.name}\\`` : \"\";\r\n  return {\r\n    message: `${type} error at line ${line}${grammaticalContext}:\\n${contextualMessage}`,\r\n    line,\r\n    input: subsequentText,\r\n    tokens: subsequentTokens\r\n  };\r\n}\r\n\r\n/**\r\n * @param {string} message error message\r\n */\r\nexport function syntaxError(source, position, current, message) {\r\n  return error(source, position, current, message, \"Syntax\");\r\n}\r\n\r\n/**\r\n * @param {string} message error message\r\n */\r\nexport function validationError(source, token, current, message) {\r\n  return error(source, token.index, current, message, \"Validation\").message;\r\n}\r\n","import { syntaxError } from \"./error.js\";\r\n\r\n// These regular expressions use the sticky flag so they will only match at\r\n// the current location (ie. the offset of lastIndex).\r\nconst tokenRe = {\r\n  // This expression uses a lookahead assertion to catch false matches\r\n  // against integers early.\r\n  \"decimal\": /-?(?=[0-9]*\\.|[0-9]+[eE])(([0-9]+\\.[0-9]*|[0-9]*\\.[0-9]+)([Ee][-+]?[0-9]+)?|[0-9]+[Ee][-+]?[0-9]+)/y,\r\n  \"integer\": /-?(0([Xx][0-9A-Fa-f]+|[0-7]*)|[1-9][0-9]*)/y,\r\n  \"identifier\": /[_-]?[A-Za-z][0-9A-Z_a-z-]*/y,\r\n  \"string\": /\"[^\"]*\"/y,\r\n  \"whitespace\": /[\\t\\n\\r ]+/y,\r\n  \"comment\": /((\\/(\\/.*|\\*([^*]|\\*[^/])*\\*\\/)[\\t\\n\\r ]*)+)/y,\r\n  \"other\": /[^\\t\\n\\r 0-9A-Za-z]/y\r\n};\r\n\r\nexport const stringTypes = [\r\n  \"ByteString\",\r\n  \"DOMString\",\r\n  \"USVString\"\r\n];\r\n\r\nexport const argumentNameKeywords = [\r\n  \"attribute\",\r\n  \"callback\",\r\n  \"const\",\r\n  \"deleter\",\r\n  \"dictionary\",\r\n  \"enum\",\r\n  \"getter\",\r\n  \"includes\",\r\n  \"inherit\",\r\n  \"interface\",\r\n  \"iterable\",\r\n  \"maplike\",\r\n  \"namespace\",\r\n  \"partial\",\r\n  \"required\",\r\n  \"setlike\",\r\n  \"setter\",\r\n  \"static\",\r\n  \"stringifier\",\r\n  \"typedef\",\r\n  \"unrestricted\"\r\n];\r\n\r\nconst nonRegexTerminals = [\r\n  \"-Infinity\",\r\n  \"FrozenArray\",\r\n  \"Infinity\",\r\n  \"NaN\",\r\n  \"Promise\",\r\n  \"boolean\",\r\n  \"byte\",\r\n  \"double\",\r\n  \"false\",\r\n  \"float\",\r\n  \"implements\",\r\n  \"legacyiterable\",\r\n  \"long\",\r\n  \"mixin\",\r\n  \"null\",\r\n  \"octet\",\r\n  \"optional\",\r\n  \"or\",\r\n  \"readonly\",\r\n  \"record\",\r\n  \"sequence\",\r\n  \"short\",\r\n  \"true\",\r\n  \"unsigned\",\r\n  \"void\"\r\n].concat(argumentNameKeywords, stringTypes);\r\n\r\nconst punctuations = [\r\n  \"(\",\r\n  \")\",\r\n  \",\",\r\n  \"...\",\r\n  \":\",\r\n  \";\",\r\n  \"<\",\r\n  \"=\",\r\n  \">\",\r\n  \"?\",\r\n  \"[\",\r\n  \"]\",\r\n  \"{\",\r\n  \"}\"\r\n];\r\n\r\n/**\r\n * @param {string} str\r\n */\r\nfunction tokenise(str) {\r\n  const tokens = [];\r\n  let lastCharIndex = 0;\r\n  let trivia = \"\";\r\n  let line = 1;\r\n  let index = 0;\r\n  while (lastCharIndex < str.length) {\r\n    const nextChar = str.charAt(lastCharIndex);\r\n    let result = -1;\r\n\r\n    if (/[\\t\\n\\r ]/.test(nextChar)) {\r\n      result = attemptTokenMatch(\"whitespace\", { noFlushTrivia: true });\r\n    } else if (nextChar === '/') {\r\n      result = attemptTokenMatch(\"comment\", { noFlushTrivia: true });\r\n    }\r\n\r\n    if (result !== -1) {\r\n      const currentTrivia = tokens.pop().value;\r\n      line += (currentTrivia.match(/\\n/g) || []).length;\r\n      trivia += currentTrivia;\r\n      index -= 1;\r\n    } else if (/[-0-9.A-Z_a-z]/.test(nextChar)) {\r\n      result = attemptTokenMatch(\"decimal\");\r\n      if (result === -1) {\r\n        result = attemptTokenMatch(\"integer\");\r\n      }\r\n      if (result === -1) {\r\n        result = attemptTokenMatch(\"identifier\");\r\n        const token = tokens[tokens.length - 1];\r\n        if (result !== -1 && nonRegexTerminals.includes(token.value)) {\r\n          token.type = token.value;\r\n        }\r\n      }\r\n    } else if (nextChar === '\"') {\r\n      result = attemptTokenMatch(\"string\");\r\n    }\r\n\r\n    for (const punctuation of punctuations) {\r\n      if (str.startsWith(punctuation, lastCharIndex)) {\r\n        tokens.push({ type: punctuation, value: punctuation, trivia, line, index });\r\n        trivia = \"\";\r\n        lastCharIndex += punctuation.length;\r\n        result = lastCharIndex;\r\n        break;\r\n      }\r\n    }\r\n\r\n    // other as the last try\r\n    if (result === -1) {\r\n      result = attemptTokenMatch(\"other\");\r\n    }\r\n    if (result === -1) {\r\n      throw new Error(\"Token stream not progressing\");\r\n    }\r\n    lastCharIndex = result;\r\n    index += 1;\r\n  }\r\n\r\n  // remaining trivia as eof\r\n  tokens.push({\r\n    type: \"eof\",\r\n    value: \"\",\r\n    trivia\r\n  });\r\n\r\n  return tokens;\r\n\r\n  /**\r\n   * @param {keyof tokenRe} type\r\n   * @param {object} [options]\r\n   * @param {boolean} [options.noFlushTrivia]\r\n   */\r\n  function attemptTokenMatch(type, { noFlushTrivia } = {}) {\r\n    const re = tokenRe[type];\r\n    re.lastIndex = lastCharIndex;\r\n    const result = re.exec(str);\r\n    if (result) {\r\n      tokens.push({ type, value: result[0], trivia, line, index });\r\n      if (!noFlushTrivia) {\r\n        trivia = \"\";\r\n      }\r\n      return re.lastIndex;\r\n    }\r\n    return -1;\r\n  }\r\n}\r\n\r\nexport class Tokeniser {\r\n  /**\r\n   * @param {string} idl\r\n   */\r\n  constructor(idl) {\r\n    this.source = tokenise(idl);\r\n    this.position = 0;\r\n  }\r\n\r\n  /**\r\n   * @param {string} message\r\n   */\r\n  error(message) {\r\n    throw new WebIDLParseError(syntaxError(this.source, this.position, this.current, message));\r\n  }\r\n\r\n  /**\r\n   * @param {string} type\r\n   */\r\n  probe(type) {\r\n    return this.source.length > this.position && this.source[this.position].type === type;\r\n  }\r\n\r\n  /**\r\n   * @param  {...string} candidates\r\n   */\r\n  consume(...candidates) {\r\n    for (const type of candidates) {\r\n      if (!this.probe(type)) continue;\r\n      const token = this.source[this.position];\r\n      this.position++;\r\n      return token;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * @param {number} position\r\n   */\r\n  unconsume(position) {\r\n    this.position = position;\r\n  }\r\n}\r\n\r\nclass WebIDLParseError extends Error {\r\n  constructor({ message, line, input, tokens }) {\r\n    super(message);\r\n    this.name = \"WebIDLParseError\"; // not to be mangled\r\n    this.line = line;\r\n    this.input = input;\r\n    this.tokens = tokens;\r\n  }\r\n}\r\n","import { Base } from \"./base.js\";\nimport { unescape, type_with_extended_attributes, return_type, primitive_type } from \"./helpers.js\";\nimport { stringTypes } from \"../tokeniser.js\";\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n * @param {string} typeName\n */\nfunction generic_type(tokeniser, typeName) {\n  const base = tokeniser.consume(\"FrozenArray\", \"Promise\", \"sequence\", \"record\");\n  if (!base) {\n    return;\n  }\n  const ret = new Type({ source: tokeniser.source, tokens: { base } });\n  ret.tokens.open = tokeniser.consume(\"<\") || tokeniser.error(`No opening bracket after ${base.type}`);\n  switch (base.type) {\n    case \"Promise\": {\n      if (tokeniser.probe(\"[\")) tokeniser.error(\"Promise type cannot have extended attribute\");\n      const subtype = return_type(tokeniser, typeName) || tokeniser.error(\"Missing Promise subtype\");\n      ret.subtype.push(subtype);\n      break;\n    }\n    case \"sequence\":\n    case \"FrozenArray\": {\n      const subtype = type_with_extended_attributes(tokeniser, typeName) || tokeniser.error(`Missing ${base.type} subtype`);\n      ret.subtype.push(subtype);\n      break;\n    }\n    case \"record\": {\n      if (tokeniser.probe(\"[\")) tokeniser.error(\"Record key cannot have extended attribute\");\n      const keyType = tokeniser.consume(...stringTypes) || tokeniser.error(`Record key must be one of: ${stringTypes.join(\", \")}`);\n      const keyIdlType = new Type({ source: tokeniser.source, tokens: { base: keyType }});\n      keyIdlType.tokens.separator = tokeniser.consume(\",\") || tokeniser.error(\"Missing comma after record key type\");\n      keyIdlType.type = typeName;\n      const valueType = type_with_extended_attributes(tokeniser, typeName) || tokeniser.error(\"Error parsing generic type record\");\n      ret.subtype.push(keyIdlType, valueType);\n      break;\n    }\n  }\n  if (!ret.idlType) tokeniser.error(`Error parsing generic type ${base.type}`);\n  ret.tokens.close = tokeniser.consume(\">\") || tokeniser.error(`Missing closing bracket after ${base.type}`);\n  return ret;\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n */\nfunction type_suffix(tokeniser, obj) {\n  const nullable = tokeniser.consume(\"?\");\n  if (nullable) {\n    obj.tokens.nullable = nullable;\n  }\n  if (tokeniser.probe(\"?\")) tokeniser.error(\"Can't nullable more than once\");\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n * @param {string} typeName\n */\nfunction single_type(tokeniser, typeName) {\n  let ret = generic_type(tokeniser, typeName) || primitive_type(tokeniser);\n  if (!ret) {\n    const base = tokeniser.consume(\"identifier\", ...stringTypes);\n    if (!base) {\n      return;\n    }\n    ret = new Type({ source: tokeniser.source, tokens: { base } });\n    if (tokeniser.probe(\"<\")) tokeniser.error(`Unsupported generic type ${base.value}`);\n  }\n  if (ret.generic === \"Promise\" && tokeniser.probe(\"?\")) {\n    tokeniser.error(\"Promise type cannot be nullable\");\n  }\n  ret.type = typeName || null;\n  type_suffix(tokeniser, ret);\n  if (ret.nullable && ret.idlType === \"any\") tokeniser.error(\"Type `any` cannot be made nullable\");\n  return ret;\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n * @param {string} type\n */\nfunction union_type(tokeniser, type) {\n  const tokens = {};\n  tokens.open = tokeniser.consume(\"(\");\n  if (!tokens.open) return;\n  const ret = new Type({ source: tokeniser.source, tokens });\n  ret.type = type || null;\n  while (true) {\n    const typ = type_with_extended_attributes(tokeniser) || tokeniser.error(\"No type after open parenthesis or 'or' in union type\");\n    if (typ.idlType === \"any\") tokeniser.error(\"Type `any` cannot be included in a union type\");\n    ret.subtype.push(typ);\n    const or = tokeniser.consume(\"or\");\n    if (or) {\n      typ.tokens.separator = or;\n    }\n    else break;\n  }\n  if (ret.idlType.length < 2) {\n    tokeniser.error(\"At least two types are expected in a union type but found less\");\n  }\n  tokens.close = tokeniser.consume(\")\") || tokeniser.error(\"Unterminated union type\");\n  type_suffix(tokeniser, ret);\n  return ret;\n}\n\nexport class Type extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   * @param {string} typeName\n   */\n  static parse(tokeniser, typeName) {\n    return single_type(tokeniser, typeName) || union_type(tokeniser, typeName);\n  }\n\n  constructor({ source, tokens }) {\n    super({ source, tokens });\n    Object.defineProperty(this, \"subtype\", { value: [] });\n    this.extAttrs = [];\n  }\n\n  get generic() {\n    if (this.subtype.length && this.tokens.base) {\n      return this.tokens.base.value;\n    }\n    return \"\";\n  }\n  get nullable() {\n    return Boolean(this.tokens.nullable);\n  }\n  get union() {\n    return Boolean(this.subtype.length) && !this.tokens.base;\n  }\n  get idlType() {\n    if (this.subtype.length) {\n      return this.subtype;\n    }\n    // Adding prefixes/postfixes for \"unrestricted float\", etc.\n    const name = [\n      this.tokens.prefix,\n      this.tokens.base,\n      this.tokens.postfix\n    ].filter(t => t).map(t => t.value).join(\" \");\n    return unescape(name);\n  }\n}\n","import { Base } from \"./base.js\";\nimport { const_data, const_value } from \"./helpers.js\";\n\nexport class Default extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const assign = tokeniser.consume(\"=\");\n    if (!assign) {\n      return null;\n    }\n    const def = const_value(tokeniser) || tokeniser.consume(\"string\", \"null\", \"[\", \"{\") || tokeniser.error(\"No value for default\");\n    const expression = [def];\n    if (def.type === \"[\") {\n      const close = tokeniser.consume(\"]\") || tokeniser.error(\"Default sequence value must be empty\");\n      expression.push(close);\n    } else if (def.type === \"{\") {\n      const close = tokeniser.consume(\"}\") || tokeniser.error(\"Default dictionary value must be empty\");\n      expression.push(close);\n    }\n    return new Default({ source: tokeniser.source, tokens: { assign }, expression });\n  }\n\n  constructor({ source, tokens, expression }) {\n    super({ source, tokens });\n    Object.defineProperty(this, \"expression\", { value: expression });\n  }\n\n  get type() {\n    return const_data(this.expression[0]).type;\n  }\n  get value() {\n    return const_data(this.expression[0]).value;\n  }\n  get negative() {\n    return const_data(this.expression[0]).negative;\n  }\n}\n","export class ArrayBase extends Array {\r\n  constructor({ source, tokens }) {\r\n    super();\r\n    Object.defineProperties(this, {\r\n      source: { value: source },\r\n      tokens: { value: tokens }\r\n    });\r\n  }\r\n}\r\n","import { Base } from \"./base.js\";\nimport { ArrayBase } from \"./array-base.js\";\nimport { list, identifiers, argument_list } from \"./helpers.js\";\n\nclass ExtendedAttributeParameters extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const tokens = { assign: tokeniser.consume(\"=\") };\n    const ret = new ExtendedAttributeParameters({ source: tokeniser.source, tokens });\n    if (tokens.assign) {\n      tokens.secondaryName = tokeniser.consume(\"identifier\", \"decimal\", \"integer\", \"string\");\n    }\n    tokens.open = tokeniser.consume(\"(\");\n    if (tokens.open) {\n      ret.list = ret.rhsType === \"identifier-list\" ?\n        // [Exposed=(Window,Worker)]\n        identifiers(tokeniser) :\n        // [NamedConstructor=Audio(DOMString src)] or [Constructor(DOMString str)]\n        argument_list(tokeniser);\n      tokens.close = tokeniser.consume(\")\") || tokeniser.error(\"Unexpected token in extended attribute argument list\");\n    } else if (ret.hasRhs && !tokens.secondaryName) {\n      tokeniser.error(\"No right hand side to extended attribute assignment\");\n    }\n    return ret;\n  }\n\n  get rhsType() {\n    return !this.tokens.assign ? null :\n      !this.tokens.secondaryName ? \"identifier-list\" :\n        this.tokens.secondaryName.type;\n  }\n}\n\nclass SimpleExtendedAttribute extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const name = tokeniser.consume(\"identifier\");\n    if (name) {\n      return new SimpleExtendedAttribute({\n        tokens: { name },\n        params: ExtendedAttributeParameters.parse(tokeniser)\n      });\n    }\n  }\n\n  constructor({ source, tokens, params }) {\n    super({ source, tokens });\n    Object.defineProperty(this, \"params\", { value: params });\n  }\n\n  get type() {\n    return \"extended-attribute\";\n  }\n  get name() {\n    return this.tokens.name.value;\n  }\n  get rhs() {\n    const { rhsType: type, tokens, list } = this.params;\n    if (!type) {\n      return null;\n    }\n    const value = type === \"identifier-list\" ? list : tokens.secondaryName.value;\n    return { type, value };\n  }\n  get arguments() {\n    const { rhsType, list } = this.params;\n    if (!list || rhsType === \"identifier-list\") {\n      return [];\n    }\n    return list;\n  }\n}\n\n// Note: we parse something simpler than the official syntax. It's all that ever\n// seems to be used\nexport class ExtendedAttributes extends ArrayBase {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const tokens = {};\n    tokens.open = tokeniser.consume(\"[\");\n    if (!tokens.open) return [];\n    const ret = new ExtendedAttributes({ source: tokeniser.source, tokens });\n    ret.push(...list(tokeniser, {\n      parser: SimpleExtendedAttribute.parse,\n      listName: \"extended attribute\"\n    }));\n    tokens.close = tokeniser.consume(\"]\") || tokeniser.error(\"Unexpected closing token of extended attribute\");\n    if (!ret.length) {\n      tokeniser.error(\"Found an empty extended attribute\");\n    }\n    if (tokeniser.probe(\"[\")) {\n      tokeniser.error(\"Illegal double extended attribute lists, consider merging them\");\n    }\n    return ret;\n  }\n}\n","import { Type } from \"./type.js\";\nimport { Argument } from \"./argument.js\";\nimport { Token } from \"./token.js\";\nimport { ExtendedAttributes } from \"./extended-attributes.js\";\n\n/**\n * @param {string} identifier\n */\nexport function unescape(identifier) {\n  return identifier.startsWith('_') ? identifier.slice(1) : identifier;\n}\n\n/**\n * Parses comma-separated list\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n * @param {object} args\n * @param {Function} args.parser parser function for each item\n * @param {boolean} [args.allowDangler] whether to allow dangling comma\n * @param {string} [args.listName] the name to be shown on error messages\n */\nexport function list(tokeniser, { parser, allowDangler, listName = \"list\" }) {\n  const first = parser(tokeniser);\n  if (!first) {\n    return [];\n  }\n  first.tokens.separator = tokeniser.consume(\",\");\n  const items = [first];\n  while (first.tokens.separator) {\n    const item = parser(tokeniser);\n    if (!item) {\n      if (!allowDangler) {\n        tokeniser.error(`Trailing comma in ${listName}`);\n      }\n      break;\n    }\n    item.tokens.separator = tokeniser.consume(\",\");\n    items.push(item);\n    if (!item.tokens.separator) break;\n  }\n  return items;\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n */\nexport function const_value(tokeniser) {\n  return tokeniser.consume(\"true\", \"false\", \"Infinity\", \"-Infinity\", \"NaN\", \"decimal\", \"integer\");\n}\n\n/**\n * @param {object} token\n * @param {string} token.type\n * @param {string} token.value\n */\nexport function const_data({ type, value }) {\n  switch (type) {\n    case \"true\":\n    case \"false\":\n      return { type: \"boolean\", value: type === \"true\" };\n    case \"Infinity\":\n    case \"-Infinity\":\n      return { type: \"Infinity\", negative: type.startsWith(\"-\") };\n    case \"[\":\n      return { type: \"sequence\", value: [] };\n    case \"{\":\n      return { type: \"dictionary\" };\n    case \"decimal\":\n    case \"integer\":\n      return { type: \"number\", value };\n    case \"string\":\n      return { type: \"string\", value: value.slice(1, -1) };\n    default:\n      return { type };\n  }\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n */\nexport function primitive_type(tokeniser) {\n  function integer_type() {\n    const prefix = tokeniser.consume(\"unsigned\");\n    const base = tokeniser.consume(\"short\", \"long\");\n    if (base) {\n      const postfix = tokeniser.consume(\"long\");\n      return new Type({ source, tokens: { prefix, base, postfix } });\n    }\n    if (prefix) tokeniser.error(\"Failed to parse integer type\");\n  }\n\n  function decimal_type() {\n    const prefix = tokeniser.consume(\"unrestricted\");\n    const base = tokeniser.consume(\"float\", \"double\");\n    if (base) {\n      return new Type({ source, tokens: { prefix, base } });\n    }\n    if (prefix) tokeniser.error(\"Failed to parse float type\");\n  }\n\n  const { source } = tokeniser;\n  const num_type = integer_type(tokeniser) || decimal_type(tokeniser);\n  if (num_type) return num_type;\n  const base = tokeniser.consume(\"boolean\", \"byte\", \"octet\");\n  if (base) {\n    return new Type({ source, tokens: { base } });\n  }\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n */\nexport function identifiers(tokeniser) {\n  const ids = list(tokeniser, { parser: Token.parser(tokeniser, \"identifier\"), listName: \"identifier list\" });\n  if (!ids.length) {\n    tokeniser.error(\"Expected identifiers but none found\");\n  }\n  return ids;\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n */\nexport function argument_list(tokeniser) {\n  return list(tokeniser, { parser: Argument.parse, listName: \"arguments list\" });\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n * @param {string} typeName\n */\nexport function type_with_extended_attributes(tokeniser, typeName) {\n  const extAttrs = ExtendedAttributes.parse(tokeniser);\n  const ret = Type.parse(tokeniser, typeName);\n  if (ret) ret.extAttrs = extAttrs;\n  return ret;\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n * @param {string} typeName\n */\nexport function return_type(tokeniser, typeName) {\n  const typ = Type.parse(tokeniser, typeName || \"return-type\");\n  if (typ) {\n    return typ;\n  }\n  const voidToken = tokeniser.consume(\"void\");\n  if (voidToken) {\n    const ret = new Type({ source: tokeniser.source, tokens: { base: voidToken } });\n    ret.type = \"return-type\";\n    return ret;\n  }\n}\n","import { Base } from \"./base.js\";\nimport { Default } from \"./default.js\";\nimport { ExtendedAttributes } from \"./extended-attributes.js\";\nimport { unescape, type_with_extended_attributes } from \"./helpers.js\";\nimport { argumentNameKeywords } from \"../tokeniser.js\";\n\nexport class Argument extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const start_position = tokeniser.position;\n    const tokens = {};\n    const ret = new Argument({ source: tokeniser.source, tokens });\n    ret.extAttrs = ExtendedAttributes.parse(tokeniser);\n    tokens.optional = tokeniser.consume(\"optional\");\n    ret.idlType = type_with_extended_attributes(tokeniser, \"argument-type\");\n    if (!ret.idlType) {\n      return tokeniser.unconsume(start_position);\n    }\n    if (!tokens.optional) {\n      tokens.variadic = tokeniser.consume(\"...\");\n    }\n    tokens.name = tokeniser.consume(\"identifier\", ...argumentNameKeywords);\n    if (!tokens.name) {\n      return tokeniser.unconsume(start_position);\n    }\n    ret.default = tokens.optional ? Default.parse(tokeniser) : null;\n    return ret;\n  }\n\n  get optional() {\n    return !!this.tokens.optional;\n  }\n  get variadic() {\n    return !!this.tokens.variadic;\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n}\n","import { Base } from \"./base.js\";\r\n\r\nexport class Token extends Base {\r\n  /**\r\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\r\n   * @param {string} type\r\n   */\r\n  static parser(tokeniser, type) {\r\n    return () => {\r\n      const value = tokeniser.consume(type);\r\n      if (value) {\r\n        return new Token({ source: tokeniser.source, tokens: { value } });\r\n      }\r\n    };\r\n  }\r\n\r\n  get value() {\r\n    return this.tokens.value.value;\r\n  }\r\n}\r\n","import { list, unescape } from \"./helpers.js\";\r\nimport { Token } from \"./token.js\";\r\nimport { Base } from \"./base.js\";\r\n\r\nclass EnumValue extends Token {\r\n  /**\r\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\r\n   */\r\n  static parse(tokeniser) {\r\n    const value = tokeniser.consume(\"string\");\r\n    if (value) {\r\n      return new EnumValue({ source: tokeniser.source, tokens: { value } });\r\n    }\r\n  }\r\n\r\n  get type() {\r\n    return \"enum-value\";\r\n  }\r\n  get value() {\r\n    return super.value.slice(1, -1);\r\n  }\r\n}\r\n\r\nexport class Enum extends Base {\r\n  /**\r\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\r\n   */\r\n  static parse(tokeniser) {\r\n    const tokens = {};\r\n    tokens.base = tokeniser.consume(\"enum\");\r\n    if (!tokens.base) {\r\n      return;\r\n    }\r\n    tokens.name = tokeniser.consume(\"identifier\") || tokeniser.error(\"No name for enum\");\r\n    const ret = tokeniser.current = new Enum({ source: tokeniser.source, tokens });\r\n    tokens.open = tokeniser.consume(\"{\") || tokeniser.error(\"Bodyless enum\");\r\n    ret.values = list(tokeniser, {\r\n      parser: EnumValue.parse,\r\n      allowDangler: true,\r\n      listName: \"enumeration\"\r\n    });\r\n    if (tokeniser.probe(\"string\")) {\r\n      tokeniser.error(\"No comma between enum values\");\r\n    }\r\n    tokens.close = tokeniser.consume(\"}\") || tokeniser.error(\"Unexpected value in enum\");\r\n    if (!ret.values.length) {\r\n      tokeniser.error(\"No value in enum\");\r\n    }\r\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(\"No semicolon after enum\");\r\n    return ret;\r\n  }\r\n\r\n  get type() {\r\n    return \"enum\";\r\n  }\r\n  get name() {\r\n    return unescape(this.tokens.name.value);\r\n  }\r\n}\r\n","import { Base } from \"./base.js\";\r\nimport { unescape } from \"./helpers.js\";\r\n\r\nexport class Includes extends Base {\r\n  /**\r\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\r\n   */\r\n  static parse(tokeniser) {\r\n    const target = tokeniser.consume(\"identifier\");\r\n    if (!target) {\r\n      return;\r\n    }\r\n    const tokens = { target };\r\n    tokens.includes = tokeniser.consume(\"includes\");\r\n    if (!tokens.includes) {\r\n      tokeniser.unconsume(target.index);\r\n      return;\r\n    }\r\n    tokens.mixin = tokeniser.consume(\"identifier\") || tokeniser.error(\"Incomplete includes statement\");\r\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(\"No terminating ; for includes statement\");\r\n    return new Includes({ source: tokeniser.source, tokens });\r\n  }\r\n\r\n  get type() {\r\n    return \"includes\";\r\n  }\r\n  get target() {\r\n    return unescape(this.tokens.target.value);\r\n  }\r\n  get includes() {\r\n    return unescape(this.tokens.mixin.value);\r\n  }\r\n}\r\n","\"use strict\";\n\nimport { const_data, const_value, unescape, primitive_type, argument_list, type_with_extended_attributes, return_type } from \"./productions/helpers.js\";\nimport { Tokeniser } from \"./tokeniser.js\";\nimport { Base } from \"./productions/base.js\";\nimport { Default } from \"./productions/default.js\";\nimport { Enum } from \"./productions/enum.js\";\nimport { Includes } from \"./productions/includes.js\";\nimport { Type } from \"./productions/type.js\";\nimport { ExtendedAttributes } from \"./productions/extended-attributes.js\";\n\n/**\n * @param {Tokeniser} tokeniser\n * @param {object} options\n * @param {boolean} [options.concrete]\n */\nfunction parseByTokens(tokeniser, options) {\n  const source = tokeniser.source;\n\n  const ID = \"identifier\";\n\n  function error(str) {\n    tokeniser.error(str);\n  }\n\n  function probe(type) {\n    return tokeniser.probe(type);\n  }\n\n  function consume(...candidates) {\n    return tokeniser.consume(...candidates);\n  }\n\n  function unconsume(position) {\n    return tokeniser.unconsume(position);\n  }\n\n  class Constant extends Base {\n    static parse() {\n      const tokens = {};\n      tokens.base = consume(\"const\");\n      if (!tokens.base) {\n        return;\n      }\n      let idlType = primitive_type(tokeniser);\n      if (!idlType) {\n        const base = consume(ID) || error(\"No type for const\");\n        idlType = new Type({ source, tokens: { base } });\n      }\n      if (probe(\"?\")) {\n        error(\"Unexpected nullable constant type\");\n      }\n      idlType.type = \"const-type\";\n      tokens.name = consume(ID) || error(\"No name for const\");\n      tokens.assign = consume(\"=\") || error(\"No value assignment for const\");\n      tokens.value = const_value(tokeniser) || error(\"No value for const\");\n      tokens.termination = consume(\";\") || error(\"Unterminated const\");\n      const ret = new Constant({ source, tokens });\n      ret.idlType = idlType;\n      return ret;\n    }\n\n    get type() {\n      return \"const\";\n    }\n    get name() {\n      return unescape(this.tokens.name.value);\n    }\n    get value() {\n      return const_data(this.tokens.value);\n    }\n  }\n\n  class CallbackFunction extends Base {\n    static parse(base) {\n      const tokens = { base };\n      const ret = new CallbackFunction({ source, tokens });\n      tokens.name = consume(ID) || error(\"No name for callback\");\n      tokeniser.current = ret;\n      tokens.assign = consume(\"=\") || error(\"No assignment in callback\");\n      ret.idlType = return_type(tokeniser) || error(\"Missing return type\");\n      tokens.open = consume(\"(\") || error(\"No arguments in callback\");\n      ret.arguments = argument_list(tokeniser);\n      tokens.close = consume(\")\") || error(\"Unterminated callback\");\n      tokens.termination = consume(\";\") || error(\"Unterminated callback\");\n      return ret;\n    }\n\n    get type() {\n      return \"callback\";\n    }\n    get name() {\n      return unescape(this.tokens.name.value);\n    }\n  }\n\n  function callback() {\n    const callback = consume(\"callback\");\n    if (!callback) return;\n    const tok = consume(\"interface\");\n    if (tok) {\n      return Interface.parse(tok, { callback });\n    }\n    return CallbackFunction.parse(callback);\n  }\n\n  class Attribute extends Base {\n    static parse({ special, noInherit = false, readonly = false } = {}) {\n      const start_position = tokeniser.position;\n      const tokens = { special };\n      const ret = new Attribute({ source, tokens });\n      if (!special && !noInherit) {\n        tokens.special = consume(\"inherit\");\n      }\n      if (ret.special === \"inherit\" && probe(\"readonly\")) {\n        error(\"Inherited attributes cannot be read-only\");\n      }\n      tokens.readonly = consume(\"readonly\");\n      if (readonly && !tokens.readonly && probe(\"attribute\")) {\n        error(\"Attributes must be readonly in this context\");\n      }\n      tokens.base = consume(\"attribute\");\n      if (!tokens.base) {\n        unconsume(start_position);\n        return;\n      }\n      ret.idlType = type_with_extended_attributes(tokeniser, \"attribute-type\") || error(\"No type in attribute\");\n      switch (ret.idlType.generic) {\n        case \"sequence\":\n        case \"record\": error(`Attributes cannot accept ${ret.idlType.generic} types`);\n      }\n      tokens.name = consume(ID, \"required\") || error(\"No name in attribute\");\n      tokens.termination = consume(\";\") || error(\"Unterminated attribute\");\n      return ret;\n    }\n\n    get type() {\n      return \"attribute\";\n    }\n    get special() {\n      if (!this.tokens.special) {\n        return \"\";\n      }\n      return this.tokens.special.value;\n    }\n    get readonly() {\n      return !!this.tokens.readonly;\n    }\n    get name() {\n      return unescape(this.tokens.name.value);\n    }\n  }\n\n  class Operation extends Base {\n    static parse({ special, regular } = {}) {\n      const tokens = { special };\n      const ret = new Operation({ source, tokens });\n      if (special && special.value === \"stringifier\") {\n        tokens.termination = consume(\";\");\n        if (tokens.termination) {\n          ret.arguments = [];\n          return ret;\n        }\n      }\n      if (!special && !regular) {\n        tokens.special = consume(\"getter\", \"setter\", \"deleter\");\n      }\n      ret.idlType = return_type(tokeniser) || error(\"Missing return type\");\n      tokens.name = consume(ID);\n      tokens.open = consume(\"(\") || error(\"Invalid operation\");\n      ret.arguments = argument_list(tokeniser);\n      tokens.close = consume(\")\") || error(\"Unterminated operation\");\n      tokens.termination = consume(\";\") || error(\"Unterminated attribute\");\n      return ret;\n    }\n\n    get type() {\n      return \"operation\";\n    }\n    get name() {\n      const { name } = this.tokens;\n      if (!name) {\n        return \"\";\n      }\n      return unescape(name.value);\n    }\n    get special() {\n      if (!this.tokens.special) {\n        return \"\";\n      }\n      return this.tokens.special.value;\n    }\n  }\n\n  function static_member() {\n    const special = consume(\"static\");\n    if (!special) return;\n    const member = Attribute.parse({ special }) ||\n      Operation.parse({ special }) ||\n      error(\"No body in static member\");\n    return member;\n  }\n\n  function stringifier() {\n    const special = consume(\"stringifier\");\n    if (!special) return;\n    const member = Attribute.parse({ special }) ||\n      Operation.parse({ special }) ||\n      error(\"Unterminated stringifier\");\n    return member;\n  }\n\n  class IterableLike extends Base {\n    static parse() {\n      const start_position = tokeniser.position;\n      const tokens = {};\n      const ret = new IterableLike({ source, tokens });\n      tokens.readonly = consume(\"readonly\");\n      tokens.base = tokens.readonly ?\n        consume(\"maplike\", \"setlike\") :\n        consume(\"iterable\", \"maplike\", \"setlike\");\n      if (!tokens.base) {\n        unconsume(start_position);\n        return;\n      }\n\n      const { type } = ret;\n      const secondTypeRequired = type === \"maplike\";\n      const secondTypeAllowed = secondTypeRequired || type === \"iterable\";\n\n      tokens.open = consume(\"<\") || error(`Error parsing ${type} declaration`);\n      const first = type_with_extended_attributes(tokeniser) || error(`Error parsing ${type} declaration`);\n      ret.idlType = [first];\n      if (secondTypeAllowed) {\n        first.tokens.separator = consume(\",\");\n        if (first.tokens.separator) {\n          ret.idlType.push(type_with_extended_attributes(tokeniser));\n        }\n        else if (secondTypeRequired)\n          error(`Missing second type argument in ${type} declaration`);\n      }\n      tokens.close = consume(\">\") || error(`Unterminated ${type} declaration`);\n      tokens.termination = consume(\";\") || error(`Missing semicolon after ${type} declaration`);\n\n      return ret;\n    }\n\n    get type() {\n      return this.tokens.base.value;\n    }\n    get readonly() {\n      return !!this.tokens.readonly;\n    }\n  }\n\n  function inheritance() {\n    const colon = consume(\":\");\n    if (!colon) {\n      return {};\n    }\n    const inheritance = consume(ID) || error(\"No type in inheritance\");\n    return { colon, inheritance };\n  }\n\n  class Container extends Base {\n    static parse(instance, { type, inheritable, allowedMembers }) {\n      const { tokens } = instance;\n      tokens.name = consume(ID) || error(\"No name for interface\");\n      tokeniser.current = instance;\n      if (inheritable) {\n        Object.assign(tokens, inheritance());\n      }\n      tokens.open = consume(\"{\") || error(`Bodyless ${type}`);\n      instance.members = [];\n      while (true) {\n        tokens.close = consume(\"}\");\n        if (tokens.close) {\n          tokens.termination = consume(\";\") || error(`Missing semicolon after ${type}`);\n          return instance;\n        }\n        const ea = ExtendedAttributes.parse(tokeniser);\n        let mem;\n        for (const [parser, ...args] of allowedMembers) {\n          mem = parser(...args);\n          if (mem) {\n            break;\n          }\n        }\n        if (!mem) {\n          error(\"Unknown member\");\n        }\n        mem.extAttrs = ea;\n        instance.members.push(mem);\n      }\n    }\n\n    get partial() {\n      return !!this.tokens.partial;\n    }\n    get name() {\n      return unescape(this.tokens.name.value);\n    }\n    get inheritance() {\n      if (!this.tokens.inheritance) {\n        return null;\n      }\n      return unescape(this.tokens.inheritance.value);\n    }\n  }\n\n  class Interface extends Container {\n    static parse(base, { callback = null, partial = null } = {}) {\n      const tokens = { callback, partial, base };\n      return Container.parse(new Interface({ source, tokens }), {\n        type: \"interface\",\n        inheritable: !partial,\n        allowedMembers: [\n          [Constant.parse],\n          [static_member],\n          [stringifier],\n          [IterableLike.parse],\n          [Attribute.parse],\n          [Operation.parse]\n        ]\n      });\n    }\n\n    get type() {\n      if (this.tokens.callback) {\n        return \"callback interface\";\n      }\n      return \"interface\";\n    }\n  }\n\n  class Mixin extends Container {\n    static parse(base, { partial } = {}) {\n      const tokens = { partial, base };\n      tokens.mixin = consume(\"mixin\");\n      if (!tokens.mixin) {\n        return;\n      }\n      return Container.parse(new Mixin({ source, tokens }), {\n        type: \"interface mixin\",\n        allowedMembers: [\n          [Constant.parse],\n          [stringifier],\n          [Attribute.parse, { noInherit: true }],\n          [Operation.parse, { regular: true }]\n        ]\n      });\n    }\n\n    get type() {\n      return \"interface mixin\";\n    }\n  }\n\n  function interface_(opts) {\n    const base = consume(\"interface\");\n    if (!base) return;\n    const ret = Mixin.parse(base, opts) ||\n      Interface.parse(base, opts) ||\n      error(\"Interface has no proper body\");\n    return ret;\n  }\n\n  class Namespace extends Container {\n    static parse({ partial } = {}) {\n      const tokens = { partial };\n      tokens.base = consume(\"namespace\");\n      if (!tokens.base) {\n        return;\n      }\n      return Container.parse(new Namespace({ source, tokens }), {\n        type: \"namespace\",\n        allowedMembers: [\n          [Attribute.parse, { noInherit: true, readonly: true }],\n          [Operation.parse, { regular: true }]\n        ]\n      });\n    }\n\n    get type() {\n      return \"namespace\";\n    }\n  }\n\n  function partial() {\n    const partial = consume(\"partial\");\n    if (!partial) return;\n    return Dictionary.parse({ partial }) ||\n      interface_({ partial }) ||\n      Namespace.parse({ partial }) ||\n      error(\"Partial doesn't apply to anything\");\n  }\n\n  class Dictionary extends Container {\n    static parse({ partial } = {}) {\n      const tokens = { partial };\n      tokens.base = consume(\"dictionary\");\n      if (!tokens.base) {\n        return;\n      }\n      return Container.parse(new Dictionary({ source, tokens }), {\n        type: \"dictionary\",\n        inheritable: !partial,\n        allowedMembers: [\n          [Field.parse],\n        ]\n      });\n    }\n\n    get type() {\n      return \"dictionary\";\n    }\n  }\n\n  class Field extends Base {\n    static parse() {\n      const tokens = {};\n      const ret = new Field({ source, tokens });\n      ret.extAttrs = ExtendedAttributes.parse(tokeniser);\n      tokens.required = consume(\"required\");\n      ret.idlType = type_with_extended_attributes(tokeniser, \"dictionary-type\") || error(\"No type for dictionary member\");\n      tokens.name = consume(ID) || error(\"No name for dictionary member\");\n      ret.default = Default.parse(tokeniser);\n      if (tokens.required && ret.default) error(\"Required member must not have a default\");\n      tokens.termination = consume(\";\") || error(\"Unterminated dictionary member\");\n      return ret;\n    }\n\n    get type() {\n      return \"field\";\n    }\n    get name() {\n      return unescape(this.tokens.name.value);\n    }\n    get required() {\n      return !!this.tokens.required;\n    }\n  }\n\n  class Typedef extends Base {\n    static parse() {\n      const tokens = {};\n      const ret = new Typedef({ source, tokens });\n      tokens.base = consume(\"typedef\");\n      if (!tokens.base) {\n        return;\n      }\n      ret.idlType = type_with_extended_attributes(tokeniser, \"typedef-type\") || error(\"No type in typedef\");\n      tokens.name = consume(ID) || error(\"No name in typedef\");\n      tokeniser.current = ret;\n      tokens.termination = consume(\";\") || error(\"Unterminated typedef\");\n      return ret;\n    }\n\n    get type() {\n      return \"typedef\";\n    }\n    get name() {\n      return unescape(this.tokens.name.value);\n    }\n  }\n\n  function definition() {\n    return callback() ||\n      interface_() ||\n      partial() ||\n      Dictionary.parse() ||\n      Enum.parse(tokeniser) ||\n      Typedef.parse() ||\n      Includes.parse(tokeniser) ||\n      Namespace.parse();\n  }\n\n  function definitions() {\n    if (!source.length) return [];\n    const defs = [];\n    while (true) {\n      const ea = ExtendedAttributes.parse(tokeniser);\n      const def = definition();\n      if (!def) {\n        if (ea.length) error(\"Stray extended attributes\");\n        break;\n      }\n      def.extAttrs = ea;\n      defs.push(def);\n    }\n    const eof = consume(\"eof\");\n    if (options.concrete) {\n      defs.push(eof);\n    }\n    return defs;\n  }\n  const res = definitions();\n  if (tokeniser.position < source.length) error(\"Unrecognised tokens\");\n  return res;\n}\n\nexport function parse(str, options = {}) {\n  const tokeniser = new Tokeniser(str);\n  return parseByTokens(tokeniser, options);\n}\n","\"use strict\";\r\n\r\nfunction noop(arg) {\r\n  return arg;\r\n}\r\n\r\nconst templates = {\r\n  wrap: items => items.join(\"\"),\r\n  trivia: noop,\r\n  name: noop,\r\n  reference: noop,\r\n  type: noop,\r\n  generic: noop,\r\n  inheritance: noop,\r\n  definition: noop,\r\n  extendedAttribute: noop,\r\n  extendedAttributeReference: noop\r\n};\r\n\r\nexport function write(ast, { templates: ts = templates } = {}) {\r\n  ts = Object.assign({}, templates, ts);\r\n\r\n  function reference(raw, { unescaped, context }) {\r\n    if (!unescaped) {\r\n      unescaped = raw.startsWith(\"_\") ? raw.slice(1) : raw;\r\n    }\r\n    return ts.reference(raw, unescaped, context);\r\n  }\r\n\r\n  function token(t, wrapper = noop, ...args) {\r\n    if (!t) {\r\n      return \"\";\r\n    }\r\n    const value = wrapper(t.value, ...args);\r\n    return ts.wrap([ts.trivia(t.trivia), value]);\r\n  }\r\n\r\n  function reference_token(t, context) {\r\n    return token(t, reference, { context });\r\n  }\r\n\r\n  function name_token(t, arg) {\r\n    return token(t, ts.name, arg);\r\n  }\r\n\r\n  function type_body(it) {\r\n    if (it.union || it.generic) {\r\n      return ts.wrap([\r\n        token(it.tokens.base, ts.generic),\r\n        token(it.tokens.open),\r\n        ...it.subtype.map(type),\r\n        token(it.tokens.close)\r\n      ]);\r\n    }\r\n    const firstToken = it.tokens.prefix || it.tokens.base;\r\n    const prefix = it.tokens.prefix ? [\r\n      it.tokens.prefix.value,\r\n      ts.trivia(it.tokens.base.trivia)\r\n    ] : [];\r\n    const ref = reference(ts.wrap([\r\n      ...prefix,\r\n      it.tokens.base.value,\r\n      token(it.tokens.postfix)\r\n    ]), { unescaped: it.idlType, context: it });\r\n    return ts.wrap([ts.trivia(firstToken.trivia), ref]);\r\n  }\r\n  function type(it) {\r\n    return ts.wrap([\r\n      extended_attributes(it.extAttrs),\r\n      type_body(it),\r\n      token(it.tokens.nullable),\r\n      token(it.tokens.separator)\r\n    ]);\r\n  }\r\n  function default_(def) {\r\n    if (!def) {\r\n      return \"\";\r\n    }\r\n    return ts.wrap([\r\n      token(def.tokens.assign),\r\n      ...def.expression.map(t => token(t))\r\n    ]);\r\n  }\r\n  function argument(arg) {\r\n    return ts.wrap([\r\n      extended_attributes(arg.extAttrs),\r\n      token(arg.tokens.optional),\r\n      ts.type(type(arg.idlType)),\r\n      token(arg.tokens.variadic),\r\n      name_token(arg.tokens.name, { data: arg }),\r\n      default_(arg.default),\r\n      token(arg.tokens.separator)\r\n    ]);\r\n  }\r\n  function identifier(id, context) {\r\n    return ts.wrap([\r\n      reference_token(id.tokens.value, context),\r\n      token(id.tokens.separator)\r\n    ]);\r\n  }\r\n  function make_ext_at(it) {\r\n    const { rhsType } = it.params;\r\n    return ts.wrap([\r\n      ts.trivia(it.tokens.name.trivia),\r\n      ts.extendedAttribute(ts.wrap([\r\n        ts.extendedAttributeReference(it.name),\r\n        token(it.params.tokens.assign),\r\n        reference_token(it.params.tokens.secondaryName, it),\r\n        token(it.params.tokens.open),\r\n        ...!it.params.list ? [] :\r\n          it.params.list.map(\r\n            rhsType === \"identifier-list\" ? id => identifier(id, it) : argument\r\n          ),\r\n        token(it.params.tokens.close)\r\n      ])),\r\n      token(it.tokens.separator)\r\n    ]);\r\n  }\r\n  function extended_attributes(eats) {\r\n    if (!eats.length) return \"\";\r\n    return ts.wrap([\r\n      token(eats.tokens.open),\r\n      ...eats.map(make_ext_at),\r\n      token(eats.tokens.close)\r\n    ]);\r\n  }\r\n\r\n  function operation(it, parent) {\r\n    const body = it.idlType ? [\r\n      ts.type(type(it.idlType)),\r\n      name_token(it.tokens.name, { data: it, parent }),\r\n      token(it.tokens.open),\r\n      ts.wrap(it.arguments.map(argument)),\r\n      token(it.tokens.close),\r\n    ] : [];\r\n    return ts.definition(ts.wrap([\r\n      extended_attributes(it.extAttrs),\r\n      token(it.tokens.special),\r\n      ...body,\r\n      token(it.tokens.termination)\r\n    ]), { data: it, parent });\r\n  }\r\n\r\n  function attribute(it, parent) {\r\n    return ts.definition(ts.wrap([\r\n      extended_attributes(it.extAttrs),\r\n      token(it.tokens.special),\r\n      token(it.tokens.readonly),\r\n      token(it.tokens.base),\r\n      ts.type(type(it.idlType)),\r\n      name_token(it.tokens.name, { data: it, parent }),\r\n      token(it.tokens.termination)\r\n    ]), { data: it, parent });\r\n  }\r\n\r\n  function inheritance(inh) {\r\n    if (!inh.tokens.inheritance) {\r\n      return \"\";\r\n    }\r\n    return ts.wrap([\r\n      token(inh.tokens.colon),\r\n      ts.trivia(inh.tokens.inheritance.trivia),\r\n      ts.inheritance(reference(inh.tokens.inheritance.value, { context: inh }))\r\n    ]);\r\n  }\r\n\r\n  function container(it) {\r\n    return ts.definition(ts.wrap([\r\n      extended_attributes(it.extAttrs),\r\n      token(it.tokens.callback),\r\n      token(it.tokens.partial),\r\n      token(it.tokens.base),\r\n      token(it.tokens.mixin),\r\n      name_token(it.tokens.name, { data: it }),\r\n      inheritance(it),\r\n      token(it.tokens.open),\r\n      iterate(it.members, it),\r\n      token(it.tokens.close),\r\n      token(it.tokens.termination)\r\n    ]), { data: it });\r\n  }\r\n\r\n  function field(it, parent) {\r\n    return ts.definition(ts.wrap([\r\n      extended_attributes(it.extAttrs),\r\n      token(it.tokens.required),\r\n      ts.type(type(it.idlType)),\r\n      name_token(it.tokens.name, { data: it, parent }),\r\n      default_(it.default),\r\n      token(it.tokens.termination)\r\n    ]), { data: it, parent });\r\n  }\r\n  function const_(it, parent) {\r\n    return ts.definition(ts.wrap([\r\n      extended_attributes(it.extAttrs),\r\n      token(it.tokens.base),\r\n      ts.type(type(it.idlType)),\r\n      name_token(it.tokens.name, { data: it, parent }),\r\n      token(it.tokens.assign),\r\n      token(it.tokens.value),\r\n      token(it.tokens.termination)\r\n    ]), { data: it, parent });\r\n  }\r\n  function typedef(it) {\r\n    return ts.definition(ts.wrap([\r\n      extended_attributes(it.extAttrs),\r\n      token(it.tokens.base),\r\n      ts.type(type(it.idlType)),\r\n      name_token(it.tokens.name, { data: it }),\r\n      token(it.tokens.termination)\r\n    ]), { data: it });\r\n  }\r\n  function includes(it) {\r\n    return ts.definition(ts.wrap([\r\n      extended_attributes(it.extAttrs),\r\n      reference_token(it.tokens.target, it),\r\n      token(it.tokens.includes),\r\n      reference_token(it.tokens.mixin, it),\r\n      token(it.tokens.termination)\r\n    ]), { data: it });\r\n  }\r\n  function callback(it) {\r\n    return ts.definition(ts.wrap([\r\n      extended_attributes(it.extAttrs),\r\n      token(it.tokens.base),\r\n      name_token(it.tokens.name, { data: it }),\r\n      token(it.tokens.assign),\r\n      ts.type(type(it.idlType)),\r\n      token(it.tokens.open),\r\n      ...it.arguments.map(argument),\r\n      token(it.tokens.close),\r\n      token(it.tokens.termination),\r\n    ]), { data: it });\r\n  }\r\n  function enum_(it) {\r\n    return ts.definition(ts.wrap([\r\n      extended_attributes(it.extAttrs),\r\n      token(it.tokens.base),\r\n      name_token(it.tokens.name, { data: it }),\r\n      token(it.tokens.open),\r\n      iterate(it.values, it),\r\n      token(it.tokens.close),\r\n      token(it.tokens.termination)\r\n    ]), { data: it });\r\n  }\r\n  function enum_value(v, parent) {\r\n    return ts.wrap([\r\n      ts.trivia(v.tokens.value.trivia),\r\n      ts.definition(\r\n        ts.wrap(['\"', ts.name(v.value, { data: v, parent }), '\"']),\r\n        { data: v, parent }\r\n      ),\r\n      token(v.tokens.separator)\r\n    ]);\r\n  }\r\n  function iterable_like(it, parent) {\r\n    return ts.definition(ts.wrap([\r\n      extended_attributes(it.extAttrs),\r\n      token(it.tokens.readonly),\r\n      token(it.tokens.base, ts.generic),\r\n      token(it.tokens.open),\r\n      ts.wrap(it.idlType.map(type)),\r\n      token(it.tokens.close),\r\n      token(it.tokens.termination)\r\n    ]), { data: it, parent });\r\n  }\r\n  function eof(it) {\r\n    return ts.trivia(it.trivia);\r\n  }\r\n\r\n  const table = {\r\n    interface: container,\r\n    \"interface mixin\": container,\r\n    namespace: container,\r\n    operation,\r\n    attribute,\r\n    dictionary: container,\r\n    field,\r\n    const: const_,\r\n    typedef,\r\n    includes,\r\n    callback,\r\n    enum: enum_,\r\n    \"enum-value\": enum_value,\r\n    iterable: iterable_like,\r\n    legacyiterable: iterable_like,\r\n    maplike: iterable_like,\r\n    setlike: iterable_like,\r\n    \"callback interface\": container,\r\n    eof\r\n  };\r\n  function dispatch(it, parent) {\r\n    const dispatcher = table[it.type];\r\n    if (!dispatcher) {\r\n      throw new Error(`Type \"${it.type}\" is unsupported`);\r\n    }\r\n    return table[it.type](it, parent);\r\n  }\r\n  function iterate(things, parent) {\r\n    if (!things) return;\r\n    const results = things.map(thing => dispatch(thing, parent));\r\n    return ts.wrap(results);\r\n  }\r\n  return iterate(ast);\r\n}\r\n","\"use strict\";\r\n\r\nimport { validationError as error } from \"./error.js\";\r\n\r\nfunction groupDefinitions(all) {\r\n  const unique = new Map();\r\n  const duplicates = new Set();\r\n  const partials = new Map();\r\n  for (const def of all) {\r\n    if (def.partial) {\r\n      const array = partials.get(def.name);\r\n      if (array) {\r\n        array.push(def);\r\n      } else {\r\n        partials.set(def.name, [def]);\r\n      }\r\n      continue;\r\n    }\r\n    if (!def.name) {\r\n      continue;\r\n    }\r\n    if (!unique.has(def.name)) {\r\n      unique.set(def.name, def);\r\n    } else {\r\n      duplicates.add(def);\r\n    }\r\n  }\r\n  return { all, unique, partials, duplicates };\r\n}\r\n\r\nfunction* checkDuplicatedNames({ unique, duplicates }) {\r\n  for (const dup of duplicates) {\r\n    const { name } = dup;\r\n    const message = `The name \"${name}\" of type \"${unique.get(name).type}\" was already seen`;\r\n    yield error(dup.source, dup.tokens.name, dup, message);\r\n  }\r\n}\r\n\r\nfunction* checkInterfaceMemberDuplication(defs) {\r\n  const interfaces = [...defs.unique.values()].filter(def => def.type === \"interface\");\r\n  const includesMap = getIncludesMap();\r\n\r\n  for (const i of interfaces) {\r\n    yield* forEachInterface(i);\r\n  }\r\n\r\n  function* forEachInterface(i) {\r\n    const opNames = new Set(getOperations(i).map(op => op.name));\r\n    const partials = defs.partials.get(i.name) || [];\r\n    const mixins = includesMap.get(i.name) || [];\r\n    for (const ext of [...partials, ...mixins]) {\r\n      const additions = getOperations(ext);\r\n      yield* forEachExtension(additions, opNames, ext, i);\r\n      for (const addition of additions) {\r\n        opNames.add(addition.name);\r\n      }\r\n    }\r\n  }\r\n\r\n  function* forEachExtension(additions, existings, ext, base) {\r\n    for (const addition of additions) {\r\n      const { name } = addition;\r\n      if (name && existings.has(name)) {\r\n        const message = `The operation \"${name}\" has already been defined for the base interface \"${base.name}\" either in itself or in a mixin`;\r\n        yield error(ext.source, addition.tokens.name, ext, message);\r\n      }\r\n    }\r\n  }\r\n\r\n  function getOperations(i) {\r\n    return i.members\r\n      .filter(({type}) => type === \"operation\");\r\n  }\r\n\r\n  function getIncludesMap() {\r\n    const map = new Map();\r\n    const includes = defs.all.filter(def => def.type === \"includes\");\r\n    for (const include of includes) {\r\n      const array = map.get(include.target);\r\n      const mixin = defs.unique.get(include.includes);\r\n      if (!mixin) {\r\n        continue;\r\n      }\r\n      if (array) {\r\n        array.push(mixin);\r\n      } else {\r\n        map.set(include.target, [mixin]);\r\n      }\r\n    }\r\n    return map;\r\n  }\r\n}\r\n\r\nexport function validate(ast) {\r\n  const defs = groupDefinitions(ast);\r\n  return [\r\n    ...checkDuplicatedNames(defs),\r\n    ...checkInterfaceMemberDuplication(defs)\r\n  ];\r\n}\r\n","export { parse } from \"./lib/webidl2.js\";\r\nexport { write } from \"./lib/writer.js\";\r\nexport { validate } from \"./lib/validator.js\";\r\n"],"sourceRoot":""}